{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af57d4b7",
   "metadata": {},
   "source": [
    "###2.1 파이토치 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513fc08",
   "metadata": {},
   "source": [
    "- PyTorch에서 **텐서(Tensor)**는 데이터를 표현하는 기본 단위\n",
    "\n",
    "  > 텐서는 다차원 배열(n-dimensional array)로, 딥러닝 모델의 입력, 출력, 가중치 등을 표현하고 연산하는 데 사용\n",
    "  \n",
    "  >  텐서는 NumPy의 배열과 유사하지만, GPU 가속을 활용할 수 있다는 점에서 차별화\n",
    "\n",
    "\n",
    "- 텐서의 특징\n",
    "\n",
    "1. 다차원 배열\n",
    "\n",
    "  > 텐서는 스칼라(0차원)부터 벡터(1차원), 행렬(2차원), 고차원 배열까지 표현.\n",
    "\n",
    "    >> 스칼라(0D 텐서): 5\n",
    "\n",
    "    >> 벡터(1D 텐서): [1,2,3]\n",
    "\n",
    "    >> 행렬(2D 텐서): [[1,2],[3,4]]\n",
    "\n",
    "    >> 텐서 (3D 텐서): 여러 개의 행렬이 쌓여 있는 구조. 교재 35페이지 그림\n",
    "\n",
    "2. GPU 가속 가능\n",
    "\n",
    "  > 텐서는 CPU뿐 아니라 GPU에서도 연산이 가능.\n",
    "\n",
    "    >> GPU에서 연산하려면 텐서를 .to('cuda') 또는 .cuda()를 사용하여 GPU로 처리.\n",
    "\n",
    "3. 자동 미분 지원\n",
    "\n",
    "  > 텐서는 PyTorch의 자동 미분(Autograd) 기능과 연동\n",
    "  \n",
    "    >> 텐서 연산의 기울기를 자동으로 계산 > 텐서에 대해 수행한 연산 과정이 자동으로 기록\n",
    "\n",
    "    >> 역전파 시 해당 텐서에 대한 기울기를 자동으로 계산할 수 있게 된다\n",
    "\n",
    "    >> requires_grad=True로 설정\n",
    "    \n",
    "       -> PyTorch는 이 텐서와 관련된 모든 연산을 계산 그래프(Computational Graph)에 텐서의 연산 기록을 저장하여 역전파(backpropagation)에 활용.\n",
    "\n",
    "4. 다양한 자료형 지원\n",
    "\n",
    "  > PyTorch 텐서는 다양한 데이터 타입을 지원합니다 (e.g., float32, int64 등).\n",
    "\n",
    "    >>torch.float, torch.int, torch.bool, torch.complex64 등.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e97c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 14.9/241.3 MB 86.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 23.1/241.3 MB 58.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 29.1/241.3 MB 48.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 32.2/241.3 MB 39.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 35.1/241.3 MB 34.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 37.7/241.3 MB 30.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 40.6/241.3 MB 28.4 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 44.0/241.3 MB 26.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 47.2/241.3 MB 25.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 51.1/241.3 MB 24.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 55.3/241.3 MB 24.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 59.8/241.3 MB 24.0 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 64.5/241.3 MB 24.0 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 67.9/241.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 73.4/241.3 MB 23.5 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 78.9/241.3 MB 23.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 84.9/241.3 MB 24.0 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 91.2/241.3 MB 24.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 96.7/241.3 MB 24.6 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 101.2/241.3 MB 24.2 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 108.3/241.3 MB 24.7 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 115.6/241.3 MB 25.1 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 122.4/241.3 MB 25.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 128.2/241.3 MB 25.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 133.7/241.3 MB 25.6 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 139.5/241.3 MB 25.6 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 142.3/241.3 MB 25.3 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 148.4/241.3 MB 25.3 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 153.4/241.3 MB 25.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 158.3/241.3 MB 25.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 161.2/241.3 MB 24.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 163.8/241.3 MB 24.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 167.2/241.3 MB 24.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 171.2/241.3 MB 24.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 175.1/241.3 MB 23.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 179.6/241.3 MB 23.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 184.3/241.3 MB 23.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 189.0/241.3 MB 23.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 194.5/241.3 MB 23.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 200.3/241.3 MB 23.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 204.7/241.3 MB 23.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 208.1/241.3 MB 23.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 212.6/241.3 MB 23.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 217.3/241.3 MB 23.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 222.3/241.3 MB 23.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 227.8/241.3 MB 23.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 233.8/241.3 MB 23.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  239.9/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.3/241.3 MB 21.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  6.3/6.3 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 27.4 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 22.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   ---------------------------------------- 6/6 [torch]\n",
      "\n",
      "Successfully installed filelock-3.19.1 fsspec-2025.7.0 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91733e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11., grad_fn=<AddBackward0>)\n",
      "tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# requires_grad=True → autograd 추적 시작\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2 + 3 * x + 1   # 연산 자동 추적됨 > 자동으로 그래프에 기록\n",
    "print(y)  # tensor(11., grad_fn=<AddBackward0>)\n",
    "\n",
    "# y를 x에 대해 미분하면 2x + 3\n",
    "y.backward()   # 자동 미분 실행\n",
    "print(x.grad)  # tensor(7.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233b930",
   "metadata": {},
   "source": [
    "- 신경망 학습에서는 가중치(Weight)에 대한 **손실 함수의 미분값(gradient)**을 반복적으로 계산해야 함\n",
    "\n",
    "  > PyTorch Autograd가 이를 자동으로 해주므로, 사용자는 모델 구조와 손실 함수만 정의하면 됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ffddd",
   "metadata": {
    "id": "099ffddd"
   },
   "outputs": [],
   "source": [
    "##2.2.1 텐서 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "kZRX92aQVHLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4692,
     "status": "ok",
     "timestamp": 1715838287186,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kZRX92aQVHLF",
    "outputId": "51b480da-fda7-479a-8476-cb7ce1bc019a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치에서 텐서 표현 \n",
    "import torch\n",
    "torch.cuda.is_available() # false이면 CPU 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a92d22",
   "metadata": {},
   "source": [
    "- PyTorch의 **연산 그래프(Computational Graph)**: 37페이지 상단 그림\n",
    "\n",
    "  > 딥러닝 모델 학습 과정에서 **자동 미분(Autograd)**을 가능하게 하는 핵심 구조\n",
    "  \n",
    "  > 연산 그래프는 모델의 파라미터가 어떻게 입력 데이터에서 출력으로 전달되는지\n",
    "  \n",
    "  > 손실 함수가 어떻게 계산되는지를 나타내는 데이터의 연산 경로를 추적하는 구조.\n",
    "\n",
    "- 연산 그래프는 딥러닝에서 중요한 역전파(Backpropagation) 과정을 자동화하기 위해 필요\n",
    "\n",
    "  > 딥러닝의 목표는 손실(loss)을 최소화하기 위해 모델 파라미터(예: 가중치 𝑤와 편향 𝑏)를 학습\n",
    "  \n",
    "    >> **기울기(Gradient)**를 계산. \n",
    "\n",
    "\n",
    "1.기울기 자동 계산\n",
    "\n",
    "- PyTorch는 연산 그래프를 기반으로 기울기를 자동으로 계산\n",
    "\n",
    "   L=(wx+b - y) **2\n",
    " \n",
    "  > 연산 그래프: x*w -> +b -> -y -> **2 = 손실함수값\n",
    "\n",
    "    > L.backward() 호출 > 그래프를 역을 따라가며  체인룰 적용하여 dL/dw, dL/db, dL/dx 기울기를 자동 계산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73fbd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.0\n",
      "dL/dw: tensor(-12.)\n",
      "dL/db: tensor(-6.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 입력, 파라미터, 정답\n",
    "x = torch.tensor(2.0)\n",
    "w = torch.tensor(3.0, requires_grad=True)  # 학습할 값\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "y = torch.tensor(10.0)\n",
    "\n",
    "# 손실 함수\n",
    "L = (x * w + b - y) ** 2\n",
    "print(\"Loss:\", L.item())\n",
    "\n",
    "# 역전파\n",
    "L.backward()\n",
    "\n",
    "print(\"dL/dw:\", w.grad)  # 기울기\n",
    "print(\"dL/db:\", b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29182545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.)\n",
      "tensor(42.)\n",
      "tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "## 연산 그래프가 각 줄이 연결된다\n",
    "    \n",
    "import torch\n",
    "\n",
    "# requires_grad=True 설정된 텐서\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "w = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# 연산 정의\n",
    "y = w * x + b\n",
    "loss = y ** 2  # 손실 함수\n",
    "\n",
    "# 역전파\n",
    "loss.backward()\n",
    "\n",
    "# 각 텐서의 기울기 출력\n",
    "print(w.grad)  # dy/dw\n",
    "print(x.grad)  # dy/dx\n",
    "print(b.grad)  # dy/db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc9464",
   "metadata": {},
   "source": [
    "- 딥러닝 학습(역전파 기반의 가중치 업데이트)\n",
    "\n",
    "연산 그래프는 딥러닝 모델의 학습 과정에서 손실 함수의 기울기를 계산하고, 이를 기반으로 가중치를 업데이트.\n",
    "\n",
    "1.순전파(Forward Pass):\n",
    "\n",
    "  > 입력 데이터를 연산 그래프를 따라 계산하여 출력(예측값)을 생성.\n",
    "\n",
    "2. 손실 계산:\n",
    "\n",
    "  > 출력값과 실제 값 사이의 손실을 계산.\n",
    "\n",
    "3. 역전파(Backward Pass):\n",
    "\n",
    "  > 연산 그래프를 따라 손실 함수의 기울기를 계산.\n",
    "\n",
    "4. 가중치 업데이트:\n",
    "\n",
    "  > 기울기를 사용하여 경사하강법(Gradient Descent)으로 가중치를 업데이트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0054917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer를 활용한 가중치 업데이트\n",
    "optimizer = torch.optim.SGD([w, b], lr=0.01)\n",
    "\n",
    "# 역전파 후 가중치 업데이트\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4661d2",
   "metadata": {},
   "source": [
    "2.2.1 텐서 다루기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805e1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "------------------------\n",
      "------------------------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor([[1,2],[3,4]]))\n",
    "print('------------------------')\n",
    "#print(torch.tensor([[1,2],[3,4]], device=\"cuda:0\")) #GPU가 없다면 오류가 발생하므로 주석 처리하였습니다.\n",
    "print('------------------------')\n",
    "\n",
    "print(torch.tensor([[1,2],[3,4]], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13955c29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1715838722984,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "13955c29",
    "outputId": "9bb7554d-bda0-4672-d1fb-1c21455ac0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "cpu\n",
      "------------------------\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "cpu\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1,2],[3,4]])\n",
    "print(temp)\n",
    "print(temp.numpy()) # 텐서를 ndarray로 변환\n",
    "print(temp.device) #device 속성을 확인\n",
    "print('------------------------')\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\") #GPU가 없다면 오류가 발생하므로 주석 처리하였습니다.\n",
    "print(temp) #cpu tensor와 구분\n",
    "print(temp.device)  # 출력: cuda:0\n",
    "#print(temp.numpy()) # cuda tensor > ndarray로 변환 안된다\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\")# GPU\n",
    "print(temp.to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018550e",
   "metadata": {},
   "source": [
    "텐서의 인덱스 조작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ceaaed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838503672,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4ceaaed8",
    "outputId": "39ad090a-b964-4636-c23a-851626c9ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(temp)\n",
    "print(temp[0], temp[1], temp[-1])\n",
    "print('------------------------')\n",
    "print(temp[2:5], temp[4:-1]) #넘파이 슬라이싱과 같다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h7Qp_dpVynFf",
   "metadata": {
    "id": "h7Qp_dpVynFf"
   },
   "source": [
    "텐서 연산 및 차원 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d9751c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1715730427854,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "35d9751c",
    "outputId": "4fea9e46-2239-4f0f-a5b8-89a5e8790bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n",
      "tensor([ 3,  8, 18])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])\n",
    "print(w - v) # 벡터 연산\n",
    "print(w * v) # 벡터 연산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d75b43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838843238,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "50d75b43",
    "outputId": "2f5b2f54-a9ed-4aa3-bbbb-e600bf538c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "------------------------\n",
      "torch.Size([4])\n",
      "tensor([1, 2, 3, 4])\n",
      "------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "print('------------------------')\n",
    "print(temp.view(4,1)) # (4,1)\n",
    "print('------------------------')\n",
    "t2= temp.view(-1) # [4] - 넘파이의 reshape()과 유사\n",
    "# -1 : 남는 차원은 PyTorch가 자동으로 계산해서 채우라는 뜻\n",
    "print(t2.shape)\n",
    "print(temp.view(-1)) # (4,) - 1차원 벡터로 변환 \n",
    "print('------------------------')\n",
    "print(temp.view(1, -1)) # (1,4) > (1, ?)로 변환\n",
    "print('------------------------')\n",
    "print(temp.view(-1, 1)) # (4,1) > (?, 1)로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1f1c0",
   "metadata": {},
   "source": [
    "##2.2.2 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "GS0fS9SBSXDE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5376,
     "status": "ok",
     "timestamp": 1715730441865,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "GS0fS9SBSXDE",
    "outputId": "ad665f58-0b35-4fa4-f57b-a1293eafb113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Y1P77eHuSfX8",
   "metadata": {
    "id": "Y1P77eHuSfX8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "data=pd.read_csv('../chap09/data/class2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "glcxHZezUgJS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715839595705,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "glcxHZezUgJS",
    "outputId": "86319734-952a-4997-aec2-64dbbf1ed66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38LHO7H3U6WV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1715773184157,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "38LHO7H3U6WV",
    "outputId": "0c8b686f-1352-44be-9d13-6de856983f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[535.],\n",
      "        [433.],\n",
      "        [ nan],\n",
      "        [ nan],\n",
      "        [488.],\n",
      "        [544.]])\n"
     ]
    }
   ],
   "source": [
    "#왜 unsqueeze()를 하는가?\n",
    "x=torch.from_numpy(data['x'].values).unsqueeze(dim=1).float() # (N,1)로 변환\n",
    "y=torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2a681",
   "metadata": {},
   "source": [
    "- unsqueeze()는 PyTorch에서 텐서의 차원(dimension)을 추가하는 데 사용되는 메서드\n",
    "\n",
    "  > squeeze() 단어 뜻: 꽉 짜다, 눌러 없애다\n",
    "\n",
    "  > 기존 텐서의 특정 위치에 크기가 1인 차원을 삽입하여 텐서의 모양(shape)을 변경.\n",
    "\n",
    "  > tensor.unsqueeze(dim)\n",
    "    >> dim: 새로 추가할 차원의 위치를 지정. 음수를 사용하면 뒤에서부터 차원을 계산.\n",
    "\n",
    "    >> 결과: 지정된 위치에 크기가 1인 차원이 추가된 새로운 텐서를 반환.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7f00259",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])   # shape: (3,)\n",
    "y = x.unsqueeze(dim=0)        # shape: (1, 3)\n",
    "z = x.unsqueeze(dim=1)        # shape: (3, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ccfe08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3])  # x의 shape: (3,)\n",
    "x_unsqueezed = x.unsqueeze(0)  # dim=0에 차원을 추가\n",
    "print(x_unsqueezed.shape)  # 출력: torch.Size([1, 3])\n",
    "\n",
    "x_unsqueezed = x.unsqueeze(1)  # dim=1에 차원을 추가\n",
    "print(x_unsqueezed.shape)  # 출력: torch.Size([3, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6e04895",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97293322",
   "metadata": {},
   "source": [
    "1. torch.from_numpy(data['x'].values)\n",
    "\n",
    "- data['x'].values: NumPy 배열 형태의 데이터를 PyTorch 텐서로 변환.\n",
    "\n",
    "  > 예를 들어, data['x'].values의 형태가 (N,)라고 가정.\n",
    "\n",
    "2. .unsqueeze(dim=1)\n",
    "\n",
    "- dim=1에 크기가 1인 차원을 추가.\n",
    "\n",
    "  > 기존 텐서의 shape이 (N,)라면, unsqueeze(dim=1)의 결과는 (N, 1).\n",
    "\n",
    "    >> 이 과정은 일반적으로 딥러닝 모델에 입력 데이터를 맞추기 위해 사용.\n",
    "\n",
    "    >> 예: 입력 데이터가 2D 형태인 (N, 1)이 되어야 하는 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3634af",
   "metadata": {},
   "source": [
    "- 왜 unsqueeze(dim=1)이 필요한가?\n",
    "\n",
    "  > 많은 딥러닝 모델은 2D 입력을 필요\n",
    "  \n",
    "    >> 선형 회귀나 MLP(Multi-Layer Perceptron) 같은 모델에서는 각 입력 데이터가 (N, D) 형태(즉, N개의 샘플에 대해 D차원 특성 벡터).\n",
    "\n",
    "    >> 원래 데이터가 1D 텐서: [x1, x2, x3, ...] (shape: (N,)).\n",
    "\n",
    "    >> 2D로 변경: [[x1], [x2], [x3], ...] (shape: (N, 1)).\n",
    "\n",
    "    >> unsqueeze(dim=1)을 사용하여 2D 텐서로 확장.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9da8a8",
   "metadata": {},
   "source": [
    "- 왜 2D 입력을 쓰는가?\n",
    "\n",
    "  > 대부분의 **기본 신경망 계층(예: nn.Linear)**은 수학적으로 **행렬 곱셈 (Matrix Multiplication)**을 기반으로 동작\n",
    "  \n",
    "    >> nn.Linear(in_features, out_features)는 내부적 계산:\n",
    "\n",
    "    Y=X.WT+b\n",
    "\n",
    "  > X: 입력 데이터, shape = (N, in_features)\n",
    "\n",
    "  > W: 가중치, shape = (out_features, in_features)\n",
    "\n",
    "  > Y: 출력, shape = (N, out_features)\n",
    "\n",
    "- 입력은 반드시 (배치 크기 N, 특성 개수 F) 형태, 즉 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a205973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1724, -0.3700], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D 벡터 입력일 때\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 샘플 하나짜리 (특징 3개)\n",
    "x = torch.tensor([1.0, 2.0, 3.0])   # shape: (3,)\n",
    "\n",
    "layer = nn.Linear(3, 2)\n",
    "# 오류 발생: 1D 텐서라서 배치 차원 없음\n",
    "layer(x)\n",
    "# nn.Linear는 (N, F) 형태를 기대하는데, (3,)는 차원이 하나라서 에러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08133408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# 2D로 맞췄을 때\n",
    "x = torch.tensor([[1.0, 2.0, 3.0]])   # shape: (1, 3), 배치=1\n",
    "layer = nn.Linear(3, 2)\n",
    "y = layer(x)\n",
    "print(y.shape)   # torch.Size([1, 2])\n",
    "# 입력이 (N=1, F=3)이므로 정상 동작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d0abb",
   "metadata": {},
   "source": [
    "- PyTorch 딥러닝 모델들이 2D 입력을 요구하는 이유\n",
    "\n",
    "  > 행렬 곱 기반의 신경망 연산(Linear layer 등)이 (배치 크기, 특징 수) 2차원 입력을 전제로 설계되었기 때문이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401223d8",
   "metadata": {},
   "source": [
    "- covtype.csv는 Covertype 데이터셋으로, 미국 콜로라도주의 국립공원의 토양 및 식생 유형을 예측하기 위한 표준 데이터셋\n",
    "\n",
    "  > UCI 머신러닝 저장소에 공개되어 있으며, CSV 형식으로 다운로드."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a041531",
   "metadata": {},
   "source": [
    "Custom dataset을 만들어서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ZRkBKGQWuti",
   "metadata": {
    "id": "9ZRkBKGQWuti"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/covtype.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m       label=torch.tensor(\u001b[38;5;28mself\u001b[39m.label.iloc[idx,\u001b[32m3\u001b[39m]).int()\n\u001b[32m     16\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m sample, label\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m tensor_dataset=\u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/covtype.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m dataset=DataLoader(tensor_dataset,batch_size=\u001b[32m4\u001b[39m,shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mCustomDataset.__init__\u001b[39m\u001b[34m(self, csv_file)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,csv_file):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m   \u001b[38;5;28mself\u001b[39m.label=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/covtype.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,csv_file):\n",
    "      self.label=pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.label)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "      sample=torch.tensor(self.label.iloc[idx,0:3]).int()\n",
    "      label=torch.tensor(self.label.iloc[idx,3]).int()\n",
    "      return sample, label\n",
    "\n",
    "tensor_dataset=CustomDataset('data/covtype.csv')\n",
    "dataset=DataLoader(tensor_dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6844928",
   "metadata": {},
   "source": [
    "- PyTorch에서 **DataLoader**를 쓰는 이유\n",
    "\n",
    "  > 딥러닝 학습 과정에 맞는 효율적인 데이터 공급\n",
    "\n",
    "- DataLoader의 핵심 역할:\n",
    "\n",
    "  1) 미니배치(batch) 단위로 데이터 제공\n",
    "\n",
    "    >> 딥러닝 학습은 한 번에 모든 데이터를 쓰지 않고, 작은 덩어리(mini-batch)로 잘라서 반복 학습\n",
    "\n",
    "    >> DataLoader가 batch_size대로 데이터를 자동으로 나눠서 제공\n",
    "\n",
    "  2) 셔플(shuffle)\n",
    "\n",
    "    >> 학습할 때 매 epoch마다 데이터 순서를 섞어주는 게 중요\n",
    "\n",
    "    >> DataLoader는 shuffle=True 옵션으로 자동 처리\n",
    "\n",
    "  3) 병렬 데이터 로딩 (multiprocessing)\n",
    "\n",
    "    >> 큰 데이터셋일수록 매번 __getitem__() 호출 시 시간이 오래 걸린다.\n",
    "\n",
    "    >> num_workers 옵션을 주면 여러 프로세스가 동시에 데이터를 읽어서 GPU 연산이 놀지 않도록 CPU가 미리 준비.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b0bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: inputs=[17.0, 11.0, 6.0, 13.0], targets=[34.0, 22.0, 12.0, 26.0]\n",
      "Batch 1: inputs=[8.0, 5.0, 3.0, 16.0], targets=[16.0, 10.0, 6.0, 32.0]\n",
      "Batch 2: inputs=[0.0, 12.0, 18.0, 1.0], targets=[0.0, 24.0, 36.0, 2.0]\n",
      "Batch 3: inputs=[19.0, 15.0, 4.0, 9.0], targets=[38.0, 30.0, 8.0, 18.0]\n",
      "Batch 4: inputs=[7.0, 10.0, 2.0, 14.0], targets=[14.0, 20.0, 4.0, 28.0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 가짜 데이터셋\n",
    "x = torch.arange(20).float().unsqueeze(1)   # shape (20,1)\n",
    "y = x * 2                                   # 레이블\n",
    "\n",
    "dataset = TensorDataset(x, y)\n",
    "\n",
    "# DataLoader 정의\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# 학습 루프에서 사용\n",
    "for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "    print(f\"Batch {batch_idx}: inputs={inputs.squeeze().tolist()}, targets={targets.squeeze().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe737f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b1102b",
   "metadata": {},
   "source": [
    "### PyTorch의 DataLoader는 미니배치, 셔플, 병렬 데이터 로딩을 자동화해서 모델 학습을 빠르고 안정적으로 진행하게 도와주는 핵심 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실행 금지!!! - 굉장히 오래 걸린다 \n",
    "# dataloader는 다음과 같이 반복실행하는 기능 => 실행시키지 않아야 함\n",
    "for i,data in enumerate(dataset,0):\n",
    "    print(i,end='')\n",
    "    batch=data[0]\n",
    "    print(batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6aaf0",
   "metadata": {},
   "source": [
    "파이토치에서 제공하는 데이터셋 사용(48페이지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rUmwfd6_kvCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5807,
     "status": "ok",
     "timestamp": 1715773231058,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "rUmwfd6_kvCq",
    "outputId": "a582e146-cbd9-4a28-953a-3b05499a9b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# 파이토치 데이터세트를 다운로드 받으려면 requests 라이브러리를 설치\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c354b9",
   "metadata": {},
   "source": [
    "- 토치비전: 파이토치에서 제공하는 데이터세트들이 모여 있는 패키지\n",
    "\n",
    "  > MNIST, ImageBet 등"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7423e510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 25.8 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip3 uninstall torch torchvision\n",
    "!pip3 install torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a99daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "0.23.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)         # PyTorch 버전 출력\n",
    "print(torchvision.__version__)   # torchvision 버전 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "V6n5xvrSk7m6",
   "metadata": {
    "id": "V6n5xvrSk7m6"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(1.0,))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fTpwWvg5liXj",
   "metadata": {
    "id": "fTpwWvg5liXj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import requests\n",
    "download_root = '/chap02/data/MNIST_DATASET'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KD-uI2jmm-Vo",
   "metadata": {
    "id": "KD-uI2jmm-Vo"
   },
   "source": [
    "2.2.3 모델 정의\n",
    "\n",
    "- 파이토치에서 모델 정의: 모듈을 상속한 클래스를 사용\n",
    "\n",
    "  > 계층: 합성곱층, 선형 계층(linear layer)\n",
    "\n",
    "  > 모듈: 한 개 이상의 계층이 모여서 모듈 구성 > 클래스로 정의\n",
    "\n",
    "  > 모델: 한개의 모듈이 모델이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c69344",
   "metadata": {},
   "source": [
    "#### 단순 신경망 정의하는 방법\n",
    "\n",
    "- nn.Module을 상속받지 않고 계층으로 모델을 만들 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1EZYoRRPmylO",
   "metadata": {
    "id": "1EZYoRRPmylO"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "model = nn.Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711eca3",
   "metadata": {},
   "source": [
    "#### nn.Module()을 상속하여 정의하는 방법\n",
    "\n",
    "- PyTorch에서 nn.Module을 상속받아 사용자 정의 신경망(모델)을 만드는 전형적인 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e1ab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):                    # ① nn.Module을 상속\n",
    "  def __init__(self, inputs): # 모델에 포함될 **레이어(layer)**와 **연산(activation function)**을 정의.\n",
    "    super(MLP, self).__init__()          # ② 부모 클래스 초기화\n",
    "    self.layer = nn.Linear(inputs, 1)    # ③ 선형층 (입력 → 출력 1개)\n",
    "    self.activation = nn.Sigmoid()       # ④ 시그모이드 활성화 함수\n",
    "  \n",
    "# 모델의 순전파(forward pass) 과정 정의\n",
    "# 학습이나 추론 시 model(X)를 호출하면 내부적으로 forward()가 실행 > __call__()\n",
    "  def forward(self, X):                  # ⑤ forward() 오버라이드\n",
    "    X = self.layer(X)                    # (N, inputs) → (N, 1)\n",
    "    X = self.activation(X)               # 0~1 사이 값으로 변환\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91d2f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6281],\n",
      "        [0.6787]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 입력 특성 3개짜리 MLP 생성\n",
    "model = MLP(inputs=3)\n",
    "\n",
    "# 더미 데이터\n",
    "x = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]])\n",
    "\n",
    "# 순전파 실행\n",
    "y = model(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0690a8",
   "metadata": {},
   "source": [
    "- torch.nn.Module은 PyTorch에서 신경망 모델을 정의할 때 사용하는 기본 클래스\n",
    "\n",
    "  > 모델의 구조를 정의하고, 모델을 학습하고 평가할 때 필요한 메소드를 제공\n",
    "  \n",
    "  > forward() 메소드는 모델의 전방향 패스(forward pass) 를 정의하는 데 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "Q39CVdKV2DRE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1715773256089,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Q39CVdKV2DRE",
    "outputId": "b69d5165-01d3-422e-9821-356a240faf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0053, 0.0000, 0.0000, 0.2153, 0.1402, 0.0000, 0.0000, 0.0000, 0.3635,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1343, 0.0440, 0.0000, 0.0000, 0.0000, 0.1593,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2405, 0.1023, 0.0000, 0.0000, 0.0000, 0.0986,\n",
      "         0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = x.view(x.shape[0],-1)\n",
    "    x = self.layer3(x)\n",
    "    return x\n",
    "\n",
    "model = MLP()\n",
    "data = torch.randn(3, 3, 32, 32)  # 3개의 이미지를 생성합니다. 각 이미지는 3채널(RGB)이며, 크기는 32x32입니다.\n",
    "model = MLP()  # 입력의 차원을 데이터의 길이로\n",
    "output = model(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec339731",
   "metadata": {},
   "source": [
    "- forward() 메소드를 정의\n",
    "\n",
    "  > 모델을 호출하는 것만으로 이 메소드가 자동으로 실행\n",
    "  \n",
    "    >> model(x)와 같이 호출하면 forward() 메소드가 실행.\n",
    "\n",
    "- nn.Module 클래스는 PyTorch에서 신경망 모델을 정의할 때 사용하는 기본 클래스\n",
    "\n",
    "  > 이 클래스는 모델의 구조(Layer 정의)와 동작(Forward Pass)을 정의할 수 있는 메소드들을 제공\n",
    "  \n",
    "  > model(input_data)라고 호출할 때, PyTorch는 자동으로 forward() 메소드를 실행\n",
    "  \n",
    "    >> output = model(input_data)\n",
    "\n",
    "    >> 모델을 호출하는 model(input_data)는 __call__() 메소드를 트리거.\n",
    "\n",
    "    >> nn.Module은 __call__() 메소드를 오버라이드(재정의)한 클래스.\n",
    "    \n",
    "       이 메소드는 실제로 forward() 메소드를 호출합니다.\n",
    "\n",
    "  > nn.Module.__call__(self, *input, **kwargs):\n",
    "\n",
    "    >> forward() 메소드 호출: __call__()는 인스턴스가 호출될 때, 내부적으로 forward() 메소드를 호출."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924160b",
   "metadata": {},
   "source": [
    "#### 함수로 신경망을 정의하는 방법\n",
    "\n",
    "- 변수로 저장한 계층을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4w8Llw5iFWMR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1715773262923,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4w8Llw5iFWMR",
    "outputId": "24a8507a-8e6f-46bc-8ce6-6639136a09ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[ 0.0725],\n",
      "        [ 0.1882],\n",
      "        [ 0.2699],\n",
      "        [-0.0889],\n",
      "        [ 0.3176],\n",
      "        [ 0.2531],\n",
      "        [-0.1122],\n",
      "        [ 0.2612],\n",
      "        [ 0.2465],\n",
      "        [ 0.1523]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output) # nn.Sequential도 nn.Module을 상속받은 클래스\n",
    "    return net\n",
    "\n",
    "# 데이터 준비\n",
    "data = torch.randn(10, 1)  # 예시로 10개의 데이터 포인트를 생성합니다.\n",
    "print(data.shape)\n",
    "# 모델 생성\n",
    "model = MLP()\n",
    "# model(data) 호출 시 내부적으로 __call__ → forward() 실행 구조를 따른다.\n",
    "# nn.Sequential은 forward()에서 안에 넣은 레이어들을 순차적으로 적용\n",
    "\n",
    "# 모델 호출\n",
    "output = model(data) #data.shape = (10,1)이므로 in_features는 10이 되고 10개의 입력을 받아들임\n",
    "#  model(data)를 호출하면, MLP 클래스의 forward 메서드가 호출되면서\n",
    "##입력 데이터가 전달되고, 해당 입력 데이터에 대한 연산이 수행되어 출력이 생성됩니다.\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NKD_8M96Qxp4",
   "metadata": {
    "id": "NKD_8M96Qxp4"
   },
   "source": [
    "#### 2.2.4 모델 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "Fg5TyyvBQ2Zt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "error",
     "timestamp": 1715773784970,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Fg5TyyvBQ2Zt",
    "outputId": "7c50a3e6-e570-4d80-f70d-45cf122fdb77"
   },
   "outputs": [],
   "source": [
    "### 교재 56페이지: 모델 파라미터 코드\n",
    "from torch.optim import optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                              lr_lambda=lambda epoch: 0.95**epoch)\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader 정의\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(1, 100+1):\n",
    "    model.train()\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x) # 출력 계산 \n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward() # 역전파 학습\n",
    "        optimizer.step() # 기울기 업데이트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51b529",
   "metadata": {},
   "source": [
    "#### 2.2.5 모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "GZ8ZUtIkSr6o",
   "metadata": {
    "id": "GZ8ZUtIkSr6o"
   },
   "outputs": [],
   "source": [
    "from torch.optim import optimizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터셋과 데이터로더를 정의해야 합니다.\n",
    "# 예를 들어, 단순한 데이터셋을 만들고 데이터로더를 생성할 수 있습니다.\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 예제 데이터를 생성합니다.\n",
    "data = [(torch.randn(1), torch.randn(1)) for _ in range(100)]\n",
    "# 데이터셋을 생성합니다.\n",
    "dataset = SimpleDataset(data)\n",
    "# 데이터로더를 생성합니다.\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "model = MLP()\n",
    "\n",
    "# 손실 함수를 정의합니다.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 옵티마이저를 정의합니다.\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 스케줄러를 정의합니다.\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95**epoch)\n",
    "\n",
    "# 모델 훈련 교재 57페이지\n",
    "for epoch in range(1, 100+1):\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "# 학습 후의 모델을 사용하여 예측을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uX4zgvP4S-tG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1715845783636,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "uX4zgvP4S-tG",
    "outputId": "295f3bfd-97fc-4479-ba50-816465385334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([0.5705]), tensor([1.2116])), (tensor([0.1113]), tensor([-0.7853])), (tensor([-0.3382]), tensor([-1.3136])), (tensor([-0.2250]), tensor([-1.1769])), (tensor([0.3211]), tensor([0.0980])), (tensor([0.0604]), tensor([-0.6976])), (tensor([-0.4376]), tensor([0.1561])), (tensor([-2.8135]), tensor([-1.6216])), (tensor([-0.4019]), tensor([0.5546])), (tensor([-0.4785]), tensor([-0.4872]))]\n",
      "Input: tensor([0.5705])\n",
      "Actual Output: tensor([1.2116])\n",
      "Predicted Output: tensor([-0.1021])\n",
      "Input: tensor([0.1113])\n",
      "Actual Output: tensor([-0.7853])\n",
      "Predicted Output: tensor([-0.0411])\n",
      "Input: tensor([-0.3382])\n",
      "Actual Output: tensor([-1.3136])\n",
      "Predicted Output: tensor([0.0360])\n",
      "Input: tensor([-0.2250])\n",
      "Actual Output: tensor([-1.1769])\n",
      "Predicted Output: tensor([0.0127])\n",
      "Input: tensor([0.3211])\n",
      "Actual Output: tensor([0.0980])\n",
      "Predicted Output: tensor([-0.0647])\n",
      "Input: tensor([0.0604])\n",
      "Actual Output: tensor([-0.6976])\n",
      "Predicted Output: tensor([-0.0354])\n",
      "Input: tensor([-0.4376])\n",
      "Actual Output: tensor([0.1561])\n",
      "Predicted Output: tensor([0.0542])\n",
      "Input: tensor([-2.8135])\n",
      "Actual Output: tensor([-1.6216])\n",
      "Predicted Output: tensor([0.3096])\n",
      "Input: tensor([-0.4019])\n",
      "Actual Output: tensor([0.5546])\n",
      "Predicted Output: tensor([0.0491])\n",
      "Input: tensor([-0.4785])\n",
      "Actual Output: tensor([-0.4872])\n",
      "Predicted Output: tensor([0.0593])\n"
     ]
    }
   ],
   "source": [
    "# 예측을 수행할 테스트 데이터를 정의합니다.\n",
    "test_data = [(torch.randn(1), torch.randn(1)) for _ in range(10)]\n",
    "print(test_data)\n",
    "# 모델을 평가 모드로 설정합니다.\n",
    "model.eval()\n",
    "\n",
    "# 각 테스트 데이터에 대한 예측을 수행합니다.\n",
    "with torch.no_grad():  # 그라디언트 계산 비활성화\n",
    "    for x_test, y_test in test_data:\n",
    "        # 입력 데이터를 모델에 전달하여 예측을 수행합니다.\n",
    "        predicted_output = model(x_test)\n",
    "        print(\"Input:\", x_test)\n",
    "        print(\"Actual Output:\", y_test)\n",
    "        print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_-u-7Gt_UBIe",
   "metadata": {
    "id": "_-u-7Gt_UBIe"
   },
   "source": [
    "#### 2.2.6 모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ARr32BLLUD1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122670,
     "status": "ok",
     "timestamp": 1715744174721,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "ARr32BLLUD1a",
    "outputId": "307bff9a-a067-46ce-eaa1-cb0bde4ca220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Collecting pretty-errors==1.2.25 (from torchmetrics)\n",
      "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
      "Collecting colorama (from pretty-errors==1.2.25->torchmetrics)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
      "Successfully installed colorama-0.4.6 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 torchmetrics-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XWl_6kAhUK3z",
   "metadata": {
    "id": "XWl_6kAhUK3z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "preds = torch.randn(10,5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "num_classes = preds.size(1)  # preds 텐서의 마지막 차원의 크기를 가져옴\n",
    "#acc = torchmetrics.functional.accuracy(preds, target)\n",
    "acc = torchmetrics.functional.accuracy(preds, target, task=\"MULTICLASS\", num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CnGTKD6DUyUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1715745027026,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "CnGTKD6DUyUF",
    "outputId": "49a104dd-b171-4d49-b9be-6ead0f8ddbe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on batch 0: 0.30000001192092896\n",
      "Accuracy on batch 1: 0.30000001192092896\n",
      "Accuracy on batch 2: 0.10000000149011612\n",
      "Accuracy on batch 3: 0.30000001192092896\n",
      "Accuracy on batch 4: 0.10000000149011612\n",
      "Accuracy on batch 5: 0.10000000149011612\n",
      "Accuracy on batch 6: 0.10000000149011612\n",
      "Accuracy on batch 7: 0.20000000298023224\n",
      "Accuracy on batch 8: 0.0\n",
      "Accuracy on batch 9: 0.10000000149011612\n",
      "Accuracy on all data 0.1599999964237213\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "num_classes = 5\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "#metric = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "\n",
    "n_batches = 10\n",
    "for i in range(n_batches):\n",
    "    preds = torch.randn(10,5).softmax(dim=-1)\n",
    "    target = torch.randint(5, (10,))\n",
    "\n",
    "    acc = metric(preds, target)\n",
    "    print(f\"Accuracy on batch {i}: {acc}\")\n",
    "\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aS450QIM714i",
   "metadata": {
    "id": "aS450QIM714i"
   },
   "source": [
    "#### 2.2.7 훈련과정 모니터링\n",
    "\n",
    "- 텐서보드를 사용한 모니터링\n",
    "\n",
    "  > 학습에 사용되는 파라미터 값이 변화 내용을 시각화\n",
    "\n",
    "  > 성능을 추적, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mOuZaGIL7412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12547,
     "status": "ok",
     "timestamp": 1715771278437,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "mOuZaGIL7412",
    "outputId": "62ea6da7-52ce-4d03-ef13-017b9ebdc8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.63.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kNJCuYN78JSd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "error",
     "timestamp": 1715772152456,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kNJCuYN78JSd",
    "outputId": "a8ae6cd1-b3f2-467b-cda5-ed9d5cf86bd8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6997dc9e1cf>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"/content/drive/MyDrive/Colab Notebooks/파이토치/pytorch2023/chap02/tensorboard\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_loss = 0.0\n",
    "\n",
    "    for i, (x,y) in enumerate(dataloader):\n",
    "        x,y = x.to(device).float(), y.to(device).float()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        writer.add_scalaer(\"Loss\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "writer.cloase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e98bca",
   "metadata": {
    "id": "42e98bca"
   },
   "outputs": [],
   "source": [
    "#### 2.4 파이토치 코드 맛보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44961535",
   "metadata": {
    "id": "44961535"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb364a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "executionInfo": {
     "elapsed": 33709,
     "status": "ok",
     "timestamp": 1715847823458,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4fb364a0",
    "outputId": "e33dc709-5903-4240-96d5-6aa52bfe8bfa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b3a6bee2-1625-4c38-8126-2a5f5754deac\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b3a6bee2-1625-4c38-8126-2a5f5754deac\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving car_evaluation.csv to car_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/car_evaluation.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea085b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1715847857445,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "63ea085b",
    "outputId": "25949609-9d33-4b31-b5a0-e1f64c6a88f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1728,\n  \"fields\": [\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"high\",\n          \"low\",\n          \"vhigh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"maint\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"high\",\n          \"low\",\n          \"vhigh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doors\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"3\",\n          \"5more\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"persons\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2\",\n          \"4\",\n          \"more\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lug_capacity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"small\",\n          \"med\",\n          \"big\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"safety\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"low\",\n          \"med\",\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"acc\",\n          \"good\",\n          \"unacc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_capacity</th>\n",
       "      <th>safety</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-cff4453a-1cf2-46e6-b353-61de473fb23d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff4453a-1cf2-46e6-b353-61de473fb23d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-cff4453a-1cf2-46e6-b353-61de473fb23d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   price  maint doors persons lug_capacity safety output\n",
       "0  vhigh  vhigh     2       2        small    low  unacc\n",
       "1  vhigh  vhigh     2       2        small    med  unacc\n",
       "2  vhigh  vhigh     2       2        small   high  unacc\n",
       "3  vhigh  vhigh     2       2          med    low  unacc\n",
       "4  vhigh  vhigh     2       2          med    med  unacc"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b271bd",
   "metadata": {},
   "source": [
    "- 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854b091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1715847866514,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "1854b091",
    "outputId": "35e2b6be-5ad5-4b18-a5df-c3c1e7cbd261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 6\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "dataset.output.value_counts().plot(kind='pie', autopct='%0.05f%%', colors=['lightblue', 'lightgreen', 'orange', 'pink'], explode=(0.05, 0.05, 0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c82b06",
   "metadata": {
    "id": "73c82b06"
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fc4df",
   "metadata": {
    "id": "281fc4df"
   },
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    dataset[category] = dataset[category].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575b6ee",
   "metadata": {},
   "source": [
    "- 범주형 데이터를 텐서로 변환\n",
    "\n",
    "  > 범주형 데이터 > dataset[ategory] > 넘파이 배열 > 텐서"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4443b",
   "metadata": {},
   "source": [
    "넘파이 객체를 합칠 때 np.stack, np.concatenate\n",
    "\n",
    "- np.concatenate()\n",
    "\n",
    "  > 기존 차원을 따라 이어붙임\n",
    "\n",
    "  > 새로운 차원은 생기지 않음\n",
    "\n",
    "    >> 붙이는 축(axis)의 크기가 맞아야 한다.\n",
    "\n",
    "- np.stack()\n",
    "\n",
    "  > 새로운 차원을 추가한 뒤 그 축을 따라 쌓음\n",
    "\n",
    "  > 배열의 차원이 1 늘어남\n",
    "\n",
    "  > 모든 배열의 shape이 동일해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43feb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2],\n",
    "              [3, 4]])   # shape (2,2)\n",
    "\n",
    "b = np.array([[5, 6],\n",
    "              [7, 8]])   # shape (2,2)\n",
    "\n",
    "# axis=0 → 행 방향으로 붙이기\n",
    "c0 = np.concatenate([a, b], axis=0)\n",
    "# [[1, 2],\n",
    "#  [3, 4],\n",
    "#  [5, 6],\n",
    "#  [7, 8]]\n",
    "print(c0.shape)  # (4,2)\n",
    "\n",
    "# axis=1 → 열 방향으로 붙이기\n",
    "c1 = np.concatenate([a, b], axis=1)\n",
    "# [[1, 2, 5, 6],\n",
    "#  [3, 4, 7, 8]]\n",
    "print(c1.shape)  # (2,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a27b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2],\n",
    "              [3, 4]])   # shape (2,2)\n",
    "\n",
    "b = np.array([[5, 6],\n",
    "              [7, 8]])   # shape (2,2)\n",
    "\n",
    "# axis=0 → 새 차원(0번 축)을 만들고 그 방향으로 쌓기\n",
    "s0 = np.stack([a, b], axis=0)\n",
    "# [[[1, 2],\n",
    "#   [3, 4]],\n",
    "#\n",
    "#  [[5, 6],\n",
    "#   [7, 8]]]\n",
    "print(s0.shape)  # (2,2,2)\n",
    "\n",
    "# axis=1 → 새 차원(1번 축)에 쌓기\n",
    "s1 = np.stack([a, b], axis=1) # 행마다 나란히 \"옆에\" 붙임 >  행 단위로 나란히 쌓기\n",
    "# 행(row)마다 a와 b를 같은 위치에 끼워서 새로운 축으로 묶는다\n",
    "# [[[1, 2],\n",
    "#   [5, 6]],\n",
    "#\n",
    "#  [[3, 4],\n",
    "#   [7, 8]]]\n",
    "print(s1.shape)  # (2,2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c85467",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6],[7,8]])\n",
    "c = np.array([[5,6],[7,8],[9,10]])\n",
    "\n",
    "print(np.concatenate(a,b), axis=0)\n",
    "print('---')\n",
    "print(np.stack(a,b), axis=0)\n",
    "print('++++')\n",
    "print(np.concatenate(a,b), axis=1)\n",
    "print('---')\n",
    "print(np.stack(a,b), axis=1) # 74페이지 그림 2-29 결과와 비교 확인 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b735e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1715848096716,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "c6b735e5",
    "outputId": "f41449be-1574-466a-c17a-ee45dd5828d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 0, 2, 1],\n",
       "       [3, 3, 0, 0, 2, 2],\n",
       "       [3, 3, 0, 0, 2, 0],\n",
       "       [3, 3, 0, 0, 1, 1],\n",
       "       [3, 3, 0, 0, 1, 2],\n",
       "       [3, 3, 0, 0, 1, 0],\n",
       "       [3, 3, 0, 0, 0, 1],\n",
       "       [3, 3, 0, 0, 0, 2],\n",
       "       [3, 3, 0, 0, 0, 0],\n",
       "       [3, 3, 0, 1, 2, 1]], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = dataset['price'].cat.codes.values # 넘파이 배열로 변환 \n",
    "maint = dataset['maint'].cat.codes.values\n",
    "doors = dataset['doors'].cat.codes.values\n",
    "persons = dataset['persons'].cat.codes.values\n",
    "lug_capacity = dataset['lug_capacity'].cat.codes.values\n",
    "safety = dataset['safety'].cat.codes.values\n",
    "\n",
    "categorical_data = np.stack([price, maint, doors, persons, lug_capacity, safety], 1)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea6d73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1715848214116,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "11ea6d73",
    "outputId": "c797995e-fdbf-421f-9930-8763c919ab0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 0, 0, 2, 1],\n",
       "        [3, 3, 0, 0, 2, 2],\n",
       "        [3, 3, 0, 0, 2, 0],\n",
       "        [3, 3, 0, 0, 1, 1],\n",
       "        [3, 3, 0, 0, 1, 2],\n",
       "        [3, 3, 0, 0, 1, 0],\n",
       "        [3, 3, 0, 0, 0, 1],\n",
       "        [3, 3, 0, 0, 0, 2],\n",
       "        [3, 3, 0, 0, 0, 0],\n",
       "        [3, 3, 0, 1, 2, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 2-5 : 배열을 텐서로 변환 \n",
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    \"output\": [\"cat\", \"dog\", \"dog\", \"bird\", \"cat\"]\n",
    "})\n",
    "\n",
    "outputs = pd.get_dummies(dataset.output)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765bcab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1715848236754,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "e765bcab",
    "outputId": "eec174b9-b68c-4edd-af44-43cf89394ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 6])\n",
      "torch.Size([6912])\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-6: 레이블을 가변수로 변환  > 범주형 값을 숫자로 변환 \n",
    "outputs = pd.get_dummies(dataset.output) # 판다스의 원-핫 인코딩(one-hot encoding)\n",
    "outputs = outputs.values\n",
    "outputs = torch.tensor(outputs).flatten() # 77페이지 박스 설명 \n",
    "print(categorical_data.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f767a",
   "metadata": {},
   "source": [
    "- ravel(), reshape(), flatten(): 77페이지 박스\n",
    "\n",
    "1. ravel()\n",
    "\n",
    "  > 배열을 **1차원으로 펴서 view(원본 참조)**를 반환.\n",
    "\n",
    "    >>원본 데이터를 공유하기 때문에 수정하면 원본도 바뀔 수 있음.\n",
    "\n",
    "2. flatten()\n",
    "\n",
    "  > 배열을 **무조건 1차원으로 펴서 복사본(copy)**을 만든다.\n",
    "\n",
    "    >> 결과를 바꿔도 원본에는 영향 없음\n",
    "\n",
    "3. reshape()\n",
    "\n",
    "  > 배열을 지정한 모양으로 **새로 보기(view) 또는 복사본(copy)**으로 반환.\n",
    "\n",
    "    >> -1을 넣으면 자동 계산해서 펴줌."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c18312",
   "metadata": {},
   "source": [
    "#### 범주형 변수(categorical variable) 임베딩을 만드는 과정\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e0711",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1715779105896,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "828e0711",
    "outputId": "ae0b1728-a854-430a-ab0e-1d62a25d0032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-7 범주형 컬럼을 N차원으로 변환\n",
    "\n",
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "# categorical_columns 안에 있는 각 범주형 컬럼마다, 몇 개의 고유 카테고리가 있는지 센다\n",
    "\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "# (col_size, embedding_dim) 형태의 튜플을 만든다\n",
    "# col_size: 해당 범주형 변수의 카테고리 개수 (= 임베딩 lookup 테이블 크기)\n",
    "# embedding_dim: 임베딩 벡터 차원 수\n",
    "# 보통 경험적으로 (카테고리 개수+1)//2를 쓰고, 최대 50으로 제한 > 78페이지 코드 2-7 상단 설명 \n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38aa0b",
   "metadata": {
    "id": "de38aa0b"
   },
   "outputs": [],
   "source": [
    "# 코드 2-8 데이터세트 분리\n",
    "\n",
    "total_records = 1728\n",
    "test_records = int(total_records * .2) # 20%를 테스트 데이터로 사용\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb162b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1715779120682,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "46eb162b",
    "outputId": "6204c0ee-5140-46fe-99ce-b25e67c871de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1383\n",
      "345\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-9 데이터세트 분리 확인\n",
    "print(len(categorical_train_data))\n",
    "print(len(train_outputs))\n",
    "print(len(categorical_test_data))\n",
    "print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa67ca",
   "metadata": {
    "id": "2eaa67ca"
   },
   "outputs": [],
   "source": [
    "# 코드 2-10 모델의 네트워크 구성\n",
    "class Model(nn.Module): #nn.Module을 상속받는다\n",
    "    def __init__(self, embedding_size, output_size, layers, p=0.4):#객체 생성자, 모델에 사용될 파라미터 전달\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols # 입력층의 크기를 찾기 위해 범주형 컬럼 개수를 input_size에 저장\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "        self.layers = nn.Sequential(*all_layers) #모든 계층을 전달\n",
    "\n",
    "    def forward(self, x_categorical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909ff0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715779161756,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4909ff0e",
    "outputId": "7ae94821-419f-4147-b4b9-5d761bcb3320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0-2): 3 x Embedding(4, 2)\n",
      "    (3-5): 3 x Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#코드 2-11 모델 객체 생성\n",
    "model = Model(categorical_embedding_sizes, 4, [200,100,50], p=0.4) #output_size = 4로 전달 \n",
    "output_data = model(input_data)# forward() 메소드가 실행\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d59a6",
   "metadata": {
    "id": "301d59a6"
   },
   "outputs": [],
   "source": [
    "# 코드 2-12 모델의 파라미터 정의\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# 다중 클래스 분류용 손실 함수.\n",
    "# 모델 출력(로짓, softmax 전)과 정답 레이블을 비교해 오차(손실)를 계산\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Adam 최적화 알고리즘으로 모델 파라미터를 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "KyuD2fLKM7Px",
   "metadata": {
    "id": "KyuD2fLKM7Px"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기가 0인 x: -0.4999999999999997\n",
      "해당 지점에서의 y 값: 5.75\n"
     ]
    }
   ],
   "source": [
    "# 주어진 함수 정의\n",
    "def func(x): #sum(yi - yi_hat)**2\n",
    "    return 5 * x ** 2 + 5 * x + 7\n",
    "\n",
    "# 도함수(미분) 계산\n",
    "def derivative(x):\n",
    "    return 10 * x + 5\n",
    "\n",
    "# 경사 하강법을 사용하여 기울기가 0인 지점 찾기\n",
    "def gradient_descent(learning_rate, initial_x, epochs):\n",
    "    x = initial_x\n",
    "    for _ in range(epochs):\n",
    "        gradient = derivative(x)\n",
    "        x = x - learning_rate * gradient\n",
    "    return x\n",
    "\n",
    "# 학습률, 초기값, 반복 횟수 설정\n",
    "learning_rate = 0.01\n",
    "initial_x = 0.0\n",
    "epochs = 1000\n",
    "\n",
    "# 경사 하강법 적용하여 기울기가 0인 지점 찾기\n",
    "optimal_x = gradient_descent(learning_rate, initial_x, epochs)\n",
    "optimal_y = func(optimal_x)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"기울기가 0인 x:\", optimal_x)\n",
    "print(\"해당 지점에서의 y 값:\", optimal_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c313f",
   "metadata": {
    "id": "3d5c313f"
   },
   "outputs": [],
   "source": [
    "# 코드 2-13 GPU/CPU 사용 지정\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56492e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56492e5b",
    "outputId": "51e99adc-0975-422f-eb01-20719c4e3bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 1.58690417\n",
      "epoch:  26 loss: 1.32208347\n",
      "epoch:  51 loss: 1.25037670\n",
      "epoch:  76 loss: 1.14533412\n",
      "epoch: 101 loss: 1.04376388\n",
      "epoch: 126 loss: 0.94333309\n",
      "epoch: 151 loss: 0.82459933\n",
      "epoch: 176 loss: 0.75102794\n",
      "epoch: 201 loss: 0.70688218\n",
      "epoch: 226 loss: 0.67204970\n",
      "epoch: 251 loss: 0.65042794\n",
      "epoch: 276 loss: 0.62593251\n",
      "epoch: 301 loss: 0.61263412\n",
      "epoch: 326 loss: 0.60477704\n",
      "epoch: 351 loss: 0.58988392\n",
      "epoch: 376 loss: 0.58695173\n",
      "epoch: 401 loss: 0.57759738\n",
      "epoch: 426 loss: 0.57076532\n",
      "epoch: 451 loss: 0.57889175\n",
      "epoch: 476 loss: 0.56059849\n",
      "epoch: 500 loss: 0.5716277361\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-14 모델 학습\n",
    "epochs = 500\n",
    "aggregated_losses = []\n",
    "train_outputs = train_outputs.to(device=device, dtype=torch.int64)\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data).to(device)\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f1035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd2f1035",
    "outputId": "130d32d1-a203-4208-e327-eabb367e46fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.55816710\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-15 테스트 데이터세트로 모델 예측\n",
    "test_outputs = test_outputs.to(device=device, dtype=torch.int64)\n",
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data).to(device)\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735f451",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6735f451",
    "outputId": "cdbe9174-23c8-43c2-e82d-e71f7607d11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5791,  0.8695, -2.0905, -1.9746],\n",
      "        [ 2.3801,  1.2895, -3.7661, -3.5672],\n",
      "        [ 2.7393,  1.5828, -3.9005, -3.7467],\n",
      "        [ 2.9840,  2.0176, -4.0020, -4.0287],\n",
      "        [ 2.7245,  1.8273, -3.2561, -3.0924]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#예측 값은 4개 값 > output_size = 4로 지정\n",
    "print(y_val[:5]) # 최대 값을 가진 인덱스로 분류한 것으로 간주"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf59f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5acf59f2",
    "outputId": "f9a2ec26-2e2c-419c-d959-9c720b90bec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-17 가장 큰 값을 갖는 인덱스 확인 \n",
    "y_val = np.argmax(y_val.cpu().numpy(), axis=1)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e16502",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7e16502",
    "outputId": "91fbee59-4b85-4bbc-9854-25da410bcd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258   1]\n",
      " [ 86   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       259\n",
      "           1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.38      0.50      0.43       345\n",
      "weighted avg       0.56      0.75      0.64       345\n",
      "\n",
      "0.7478260869565218\n"
     ]
    }
   ],
   "source": [
    "# 코드 2-18 테스트 데이터세트를 사용한 정확도 확인 \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "test_outputs=test_outputs.cpu().numpy()\n",
    "print(confusion_matrix(test_outputs,y_val))\n",
    "print(classification_report(test_outputs,y_val))\n",
    "print(accuracy_score(test_outputs, y_val))\n",
    "#confusion matrix에 대한 설명: 85-86페이지\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9HAW0ADKWTM4",
   "metadata": {
    "id": "9HAW0ADKWTM4"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Vzrg4SeHdw65",
   "metadata": {
    "id": "Vzrg4SeHdw65"
   },
   "source": [
    "구글링: 2023.04.18 주피터노트북 VSCode 연동, 가상환경 만들기, GPU사용 환경 세팅(에러 해결 방법), 차유빈·2023년 4월 20일"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
