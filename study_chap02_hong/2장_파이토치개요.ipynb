{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af57d4b7",
   "metadata": {},
   "source": [
    "###2.1 íŒŒì´í† ì¹˜ ê°œìš”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8513fc08",
   "metadata": {},
   "source": [
    "- PyTorchì—ì„œ **í…ì„œ(Tensor)**ëŠ” ë°ì´í„°ë¥¼ í‘œí˜„í•˜ëŠ” ê¸°ë³¸ ë‹¨ìœ„\n",
    "\n",
    "  > í…ì„œëŠ” ë‹¤ì°¨ì› ë°°ì—´(n-dimensional array)ë¡œ, ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ ì…ë ¥, ì¶œë ¥, ê°€ì¤‘ì¹˜ ë“±ì„ í‘œí˜„í•˜ê³  ì—°ì‚°í•˜ëŠ” ë° ì‚¬ìš©\n",
    "  \n",
    "  >  í…ì„œëŠ” NumPyì˜ ë°°ì—´ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ, GPU ê°€ì†ì„ í™œìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì—ì„œ ì°¨ë³„í™”\n",
    "\n",
    "\n",
    "- í…ì„œì˜ íŠ¹ì§•\n",
    "\n",
    "1. ë‹¤ì°¨ì› ë°°ì—´\n",
    "\n",
    "  > í…ì„œëŠ” ìŠ¤ì¹¼ë¼(0ì°¨ì›)ë¶€í„° ë²¡í„°(1ì°¨ì›), í–‰ë ¬(2ì°¨ì›), ê³ ì°¨ì› ë°°ì—´ê¹Œì§€ í‘œí˜„.\n",
    "\n",
    "    >> ìŠ¤ì¹¼ë¼(0D í…ì„œ): 5\n",
    "\n",
    "    >> ë²¡í„°(1D í…ì„œ): [1,2,3]\n",
    "\n",
    "    >> í–‰ë ¬(2D í…ì„œ): [[1,2],[3,4]]\n",
    "\n",
    "    >> í…ì„œ (3D í…ì„œ): ì—¬ëŸ¬ ê°œì˜ í–‰ë ¬ì´ ìŒ“ì—¬ ìˆëŠ” êµ¬ì¡°. êµì¬ 35í˜ì´ì§€ ê·¸ë¦¼\n",
    "\n",
    "2. GPU ê°€ì† ê°€ëŠ¥\n",
    "\n",
    "  > í…ì„œëŠ” CPUë¿ ì•„ë‹ˆë¼ GPUì—ì„œë„ ì—°ì‚°ì´ ê°€ëŠ¥.\n",
    "\n",
    "    >> GPUì—ì„œ ì—°ì‚°í•˜ë ¤ë©´ í…ì„œë¥¼ .to('cuda') ë˜ëŠ” .cuda()ë¥¼ ì‚¬ìš©í•˜ì—¬ GPUë¡œ ì²˜ë¦¬.\n",
    "\n",
    "3. ìë™ ë¯¸ë¶„ ì§€ì›\n",
    "\n",
    "  > í…ì„œëŠ” PyTorchì˜ ìë™ ë¯¸ë¶„(Autograd) ê¸°ëŠ¥ê³¼ ì—°ë™\n",
    "  \n",
    "    >> í…ì„œ ì—°ì‚°ì˜ ê¸°ìš¸ê¸°ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚° > í…ì„œì— ëŒ€í•´ ìˆ˜í–‰í•œ ì—°ì‚° ê³¼ì •ì´ ìë™ìœ¼ë¡œ ê¸°ë¡\n",
    "\n",
    "    >> ì—­ì „íŒŒ ì‹œ í•´ë‹¹ í…ì„œì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ ëœë‹¤\n",
    "\n",
    "    >> requires_grad=Trueë¡œ ì„¤ì •\n",
    "    \n",
    "       -> PyTorchëŠ” ì´ í…ì„œì™€ ê´€ë ¨ëœ ëª¨ë“  ì—°ì‚°ì„ ê³„ì‚° ê·¸ë˜í”„(Computational Graph)ì— í…ì„œì˜ ì—°ì‚° ê¸°ë¡ì„ ì €ì¥í•˜ì—¬ ì—­ì „íŒŒ(backpropagation)ì— í™œìš©.\n",
    "\n",
    "4. ë‹¤ì–‘í•œ ìë£Œí˜• ì§€ì›\n",
    "\n",
    "  > PyTorch í…ì„œëŠ” ë‹¤ì–‘í•œ ë°ì´í„° íƒ€ì…ì„ ì§€ì›í•©ë‹ˆë‹¤ (e.g., float32, int64 ë“±).\n",
    "\n",
    "    >>torch.float, torch.int, torch.bool, torch.complex64 ë“±.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e97c417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.14.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec (from torch)\n",
      "  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)\n",
      "   ---------------------------------------- 0.0/241.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 14.9/241.3 MB 86.0 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 23.1/241.3 MB 58.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 29.1/241.3 MB 48.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 32.2/241.3 MB 39.8 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 35.1/241.3 MB 34.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 37.7/241.3 MB 30.9 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 40.6/241.3 MB 28.4 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 44.0/241.3 MB 26.6 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 47.2/241.3 MB 25.5 MB/s eta 0:00:08\n",
      "   -------- ------------------------------- 51.1/241.3 MB 24.7 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 55.3/241.3 MB 24.3 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 59.8/241.3 MB 24.0 MB/s eta 0:00:08\n",
      "   ---------- ----------------------------- 64.5/241.3 MB 24.0 MB/s eta 0:00:08\n",
      "   ----------- ---------------------------- 67.9/241.3 MB 23.4 MB/s eta 0:00:08\n",
      "   ------------ --------------------------- 73.4/241.3 MB 23.5 MB/s eta 0:00:08\n",
      "   ------------- -------------------------- 78.9/241.3 MB 23.7 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 84.9/241.3 MB 24.0 MB/s eta 0:00:07\n",
      "   --------------- ------------------------ 91.2/241.3 MB 24.3 MB/s eta 0:00:07\n",
      "   ---------------- ----------------------- 96.7/241.3 MB 24.6 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 101.2/241.3 MB 24.2 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 108.3/241.3 MB 24.7 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 115.6/241.3 MB 25.1 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 122.4/241.3 MB 25.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 128.2/241.3 MB 25.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 133.7/241.3 MB 25.6 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 139.5/241.3 MB 25.6 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 142.3/241.3 MB 25.3 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 148.4/241.3 MB 25.3 MB/s eta 0:00:04\n",
      "   ------------------------ -------------- 153.4/241.3 MB 25.2 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 158.3/241.3 MB 25.2 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 161.2/241.3 MB 24.8 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 163.8/241.3 MB 24.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 167.2/241.3 MB 24.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 171.2/241.3 MB 24.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 175.1/241.3 MB 23.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 179.6/241.3 MB 23.8 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 184.3/241.3 MB 23.7 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 189.0/241.3 MB 23.7 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 194.5/241.3 MB 23.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 200.3/241.3 MB 23.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 204.7/241.3 MB 23.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 208.1/241.3 MB 23.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 212.6/241.3 MB 23.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 217.3/241.3 MB 23.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 222.3/241.3 MB 23.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 227.8/241.3 MB 23.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 233.8/241.3 MB 23.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  239.9/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  241.2/241.3 MB 23.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 241.3/241.3 MB 21.5 MB/s eta 0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ---------------------------------------  6.3/6.3 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 27.4 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 536.2/536.2 kB 15.5 MB/s eta 0:00:00\n",
      "Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 22.0 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, fsspec, filelock, torch\n",
      "\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ---------------------------------------- 0/6 [mpmath]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------ --------------------------------- 1/6 [sympy]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   ------------- -------------------------- 2/6 [networkx]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   -------------------- ------------------- 3/6 [fsspec]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   --------------------------------- ------ 5/6 [torch]\n",
      "   ---------------------------------------- 6/6 [torch]\n",
      "\n",
      "Successfully installed filelock-3.19.1 fsspec-2025.7.0 mpmath-1.3.0 networkx-3.5 sympy-1.14.0 torch-2.8.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91733e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(11., grad_fn=<AddBackward0>)\n",
      "tensor(7.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# requires_grad=True â†’ autograd ì¶”ì  ì‹œì‘\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "y = x ** 2 + 3 * x + 1   # ì—°ì‚° ìë™ ì¶”ì ë¨ > ìë™ìœ¼ë¡œ ê·¸ë˜í”„ì— ê¸°ë¡\n",
    "print(y)  # tensor(11., grad_fn=<AddBackward0>)\n",
    "\n",
    "# yë¥¼ xì— ëŒ€í•´ ë¯¸ë¶„í•˜ë©´ 2x + 3\n",
    "y.backward()   # ìë™ ë¯¸ë¶„ ì‹¤í–‰\n",
    "print(x.grad)  # tensor(7.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233b930",
   "metadata": {},
   "source": [
    "- ì‹ ê²½ë§ í•™ìŠµì—ì„œëŠ” ê°€ì¤‘ì¹˜(Weight)ì— ëŒ€í•œ **ì†ì‹¤ í•¨ìˆ˜ì˜ ë¯¸ë¶„ê°’(gradient)**ì„ ë°˜ë³µì ìœ¼ë¡œ ê³„ì‚°í•´ì•¼ í•¨\n",
    "\n",
    "  > PyTorch Autogradê°€ ì´ë¥¼ ìë™ìœ¼ë¡œ í•´ì£¼ë¯€ë¡œ, ì‚¬ìš©ìëŠ” ëª¨ë¸ êµ¬ì¡°ì™€ ì†ì‹¤ í•¨ìˆ˜ë§Œ ì •ì˜í•˜ë©´ ë¨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099ffddd",
   "metadata": {
    "id": "099ffddd"
   },
   "outputs": [],
   "source": [
    "##2.2.1 í…ì„œ ë‹¤ë£¨ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "kZRX92aQVHLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4692,
     "status": "ok",
     "timestamp": 1715838287186,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kZRX92aQVHLF",
    "outputId": "51b480da-fda7-479a-8476-cb7ce1bc019a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# íŒŒì´í† ì¹˜ì—ì„œ í…ì„œ í‘œí˜„ \n",
    "import torch\n",
    "torch.cuda.is_available() # falseì´ë©´ CPU ì‚¬ìš© "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a92d22",
   "metadata": {},
   "source": [
    "- PyTorchì˜ **ì—°ì‚° ê·¸ë˜í”„(Computational Graph)**: 37í˜ì´ì§€ ìƒë‹¨ ê·¸ë¦¼\n",
    "\n",
    "  > ë”¥ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ **ìë™ ë¯¸ë¶„(Autograd)**ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” í•µì‹¬ êµ¬ì¡°\n",
    "  \n",
    "  > ì—°ì‚° ê·¸ë˜í”„ëŠ” ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ê°€ ì–´ë–»ê²Œ ì…ë ¥ ë°ì´í„°ì—ì„œ ì¶œë ¥ìœ¼ë¡œ ì „ë‹¬ë˜ëŠ”ì§€\n",
    "  \n",
    "  > ì†ì‹¤ í•¨ìˆ˜ê°€ ì–´ë–»ê²Œ ê³„ì‚°ë˜ëŠ”ì§€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ë°ì´í„°ì˜ ì—°ì‚° ê²½ë¡œë¥¼ ì¶”ì í•˜ëŠ” êµ¬ì¡°.\n",
    "\n",
    "- ì—°ì‚° ê·¸ë˜í”„ëŠ” ë”¥ëŸ¬ë‹ì—ì„œ ì¤‘ìš”í•œ ì—­ì „íŒŒ(Backpropagation) ê³¼ì •ì„ ìë™í™”í•˜ê¸° ìœ„í•´ í•„ìš”\n",
    "\n",
    "  > ë”¥ëŸ¬ë‹ì˜ ëª©í‘œëŠ” ì†ì‹¤(loss)ì„ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ëª¨ë¸ íŒŒë¼ë¯¸í„°(ì˜ˆ: ê°€ì¤‘ì¹˜ ğ‘¤ì™€ í¸í–¥ ğ‘)ë¥¼ í•™ìŠµ\n",
    "  \n",
    "    >> **ê¸°ìš¸ê¸°(Gradient)**ë¥¼ ê³„ì‚°. \n",
    "\n",
    "\n",
    "1.ê¸°ìš¸ê¸° ìë™ ê³„ì‚°\n",
    "\n",
    "- PyTorchëŠ” ì—°ì‚° ê·¸ë˜í”„ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ìš¸ê¸°ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°\n",
    "\n",
    "   L=(wx+b - y) **2\n",
    " \n",
    "  > ì—°ì‚° ê·¸ë˜í”„: x*w -> +b -> -y -> **2 = ì†ì‹¤í•¨ìˆ˜ê°’\n",
    "\n",
    "    > L.backward() í˜¸ì¶œ > ê·¸ë˜í”„ë¥¼ ì—­ì„ ë”°ë¼ê°€ë©°  ì²´ì¸ë£° ì ìš©í•˜ì—¬ dL/dw, dL/db, dL/dx ê¸°ìš¸ê¸°ë¥¼ ìë™ ê³„ì‚°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d73fbd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 9.0\n",
      "dL/dw: tensor(-12.)\n",
      "dL/db: tensor(-6.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ì…ë ¥, íŒŒë¼ë¯¸í„°, ì •ë‹µ\n",
    "x = torch.tensor(2.0)\n",
    "w = torch.tensor(3.0, requires_grad=True)  # í•™ìŠµí•  ê°’\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "y = torch.tensor(10.0)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜\n",
    "L = (x * w + b - y) ** 2\n",
    "print(\"Loss:\", L.item())\n",
    "\n",
    "# ì—­ì „íŒŒ\n",
    "L.backward()\n",
    "\n",
    "print(\"dL/dw:\", w.grad)  # ê¸°ìš¸ê¸°\n",
    "print(\"dL/db:\", b.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29182545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.)\n",
      "tensor(42.)\n",
      "tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "## ì—°ì‚° ê·¸ë˜í”„ê°€ ê° ì¤„ì´ ì—°ê²°ëœë‹¤\n",
    "    \n",
    "import torch\n",
    "\n",
    "# requires_grad=True ì„¤ì •ëœ í…ì„œ\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "w = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# ì—°ì‚° ì •ì˜\n",
    "y = w * x + b\n",
    "loss = y ** 2  # ì†ì‹¤ í•¨ìˆ˜\n",
    "\n",
    "# ì—­ì „íŒŒ\n",
    "loss.backward()\n",
    "\n",
    "# ê° í…ì„œì˜ ê¸°ìš¸ê¸° ì¶œë ¥\n",
    "print(w.grad)  # dy/dw\n",
    "print(x.grad)  # dy/dx\n",
    "print(b.grad)  # dy/db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc9464",
   "metadata": {},
   "source": [
    "- ë”¥ëŸ¬ë‹ í•™ìŠµ(ì—­ì „íŒŒ ê¸°ë°˜ì˜ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸)\n",
    "\n",
    "ì—°ì‚° ê·¸ë˜í”„ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì˜ í•™ìŠµ ê³¼ì •ì—ì„œ ì†ì‹¤ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸.\n",
    "\n",
    "1.ìˆœì „íŒŒ(Forward Pass):\n",
    "\n",
    "  > ì…ë ¥ ë°ì´í„°ë¥¼ ì—°ì‚° ê·¸ë˜í”„ë¥¼ ë”°ë¼ ê³„ì‚°í•˜ì—¬ ì¶œë ¥(ì˜ˆì¸¡ê°’)ì„ ìƒì„±.\n",
    "\n",
    "2. ì†ì‹¤ ê³„ì‚°:\n",
    "\n",
    "  > ì¶œë ¥ê°’ê³¼ ì‹¤ì œ ê°’ ì‚¬ì´ì˜ ì†ì‹¤ì„ ê³„ì‚°.\n",
    "\n",
    "3. ì—­ì „íŒŒ(Backward Pass):\n",
    "\n",
    "  > ì—°ì‚° ê·¸ë˜í”„ë¥¼ ë”°ë¼ ì†ì‹¤ í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ë¥¼ ê³„ì‚°.\n",
    "\n",
    "4. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸:\n",
    "\n",
    "  > ê¸°ìš¸ê¸°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²½ì‚¬í•˜ê°•ë²•(Gradient Descent)ìœ¼ë¡œ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0054917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizerë¥¼ í™œìš©í•œ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "optimizer = torch.optim.SGD([w, b], lr=0.01)\n",
    "\n",
    "# ì—­ì „íŒŒ í›„ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4661d2",
   "metadata": {},
   "source": [
    "2.2.1 í…ì„œ ë‹¤ë£¨ê¸° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "805e1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "------------------------\n",
      "------------------------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor([[1,2],[3,4]]))\n",
    "print('------------------------')\n",
    "#print(torch.tensor([[1,2],[3,4]], device=\"cuda:0\")) #GPUê°€ ì—†ë‹¤ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "print('------------------------')\n",
    "\n",
    "print(torch.tensor([[1,2],[3,4]], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13955c29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1715838722984,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "13955c29",
    "outputId": "9bb7554d-bda0-4672-d1fb-1c21455ac0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "cpu\n",
      "------------------------\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "cpu\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1,2],[3,4]])\n",
    "print(temp)\n",
    "print(temp.numpy()) # í…ì„œë¥¼ ndarrayë¡œ ë³€í™˜\n",
    "print(temp.device) #device ì†ì„±ì„ í™•ì¸\n",
    "print('------------------------')\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\") #GPUê°€ ì—†ë‹¤ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë¯€ë¡œ ì£¼ì„ ì²˜ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.\n",
    "print(temp) #cpu tensorì™€ êµ¬ë¶„\n",
    "print(temp.device)  # ì¶œë ¥: cuda:0\n",
    "#print(temp.numpy()) # cuda tensor > ndarrayë¡œ ë³€í™˜ ì•ˆëœë‹¤\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\")# GPU\n",
    "print(temp.to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018550e",
   "metadata": {},
   "source": [
    "í…ì„œì˜ ì¸ë±ìŠ¤ ì¡°ì‘ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ceaaed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838503672,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4ceaaed8",
    "outputId": "39ad090a-b964-4636-c23a-851626c9ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(temp)\n",
    "print(temp[0], temp[1], temp[-1])\n",
    "print('------------------------')\n",
    "print(temp[2:5], temp[4:-1]) #ë„˜íŒŒì´ ìŠ¬ë¼ì´ì‹±ê³¼ ê°™ë‹¤ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h7Qp_dpVynFf",
   "metadata": {
    "id": "h7Qp_dpVynFf"
   },
   "source": [
    "í…ì„œ ì—°ì‚° ë° ì°¨ì› ì¡°ì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35d9751c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1715730427854,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "35d9751c",
    "outputId": "4fea9e46-2239-4f0f-a5b8-89a5e8790bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n",
      "tensor([ 3,  8, 18])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])\n",
    "print(w - v) # ë²¡í„° ì—°ì‚°\n",
    "print(w * v) # ë²¡í„° ì—°ì‚° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d75b43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838843238,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "50d75b43",
    "outputId": "2f5b2f54-a9ed-4aa3-bbbb-e600bf538c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "------------------------\n",
      "torch.Size([4])\n",
      "tensor([1, 2, 3, 4])\n",
      "------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "print('------------------------')\n",
    "print(temp.view(4,1)) # (4,1)\n",
    "print('------------------------')\n",
    "t2= temp.view(-1) # [4] - ë„˜íŒŒì´ì˜ reshape()ê³¼ ìœ ì‚¬\n",
    "# -1 : ë‚¨ëŠ” ì°¨ì›ì€ PyTorchê°€ ìë™ìœ¼ë¡œ ê³„ì‚°í•´ì„œ ì±„ìš°ë¼ëŠ” ëœ»\n",
    "print(t2.shape)\n",
    "print(temp.view(-1)) # (4,) - 1ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜ \n",
    "print('------------------------')\n",
    "print(temp.view(1, -1)) # (1,4) > (1, ?)ë¡œ ë³€í™˜\n",
    "print('------------------------')\n",
    "print(temp.view(-1, 1)) # (4,1) > (?, 1)ë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1f1c0",
   "metadata": {},
   "source": [
    "##2.2.2 ë°ì´í„° ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "GS0fS9SBSXDE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5376,
     "status": "ok",
     "timestamp": 1715730441865,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "GS0fS9SBSXDE",
    "outputId": "ad665f58-0b35-4fa4-f57b-a1293eafb113"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Y1P77eHuSfX8",
   "metadata": {
    "id": "Y1P77eHuSfX8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "data=pd.read_csv('../chap09/data/class2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "glcxHZezUgJS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715839595705,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "glcxHZezUgJS",
    "outputId": "86319734-952a-4997-aec2-64dbbf1ed66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38LHO7H3U6WV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1715773184157,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "38LHO7H3U6WV",
    "outputId": "0c8b686f-1352-44be-9d13-6de856983f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[535.],\n",
      "        [433.],\n",
      "        [ nan],\n",
      "        [ nan],\n",
      "        [488.],\n",
      "        [544.]])\n"
     ]
    }
   ],
   "source": [
    "#ì™œ unsqueeze()ë¥¼ í•˜ëŠ”ê°€?\n",
    "x=torch.from_numpy(data['x'].values).unsqueeze(dim=1).float() # (N,1)ë¡œ ë³€í™˜\n",
    "y=torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2a681",
   "metadata": {},
   "source": [
    "- unsqueeze()ëŠ” PyTorchì—ì„œ í…ì„œì˜ ì°¨ì›(dimension)ì„ ì¶”ê°€í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ë©”ì„œë“œ\n",
    "\n",
    "  > squeeze() ë‹¨ì–´ ëœ»: ê½‰ ì§œë‹¤, ëˆŒëŸ¬ ì—†ì• ë‹¤\n",
    "\n",
    "  > ê¸°ì¡´ í…ì„œì˜ íŠ¹ì • ìœ„ì¹˜ì— í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì‚½ì…í•˜ì—¬ í…ì„œì˜ ëª¨ì–‘(shape)ì„ ë³€ê²½.\n",
    "\n",
    "  > tensor.unsqueeze(dim)\n",
    "    >> dim: ìƒˆë¡œ ì¶”ê°€í•  ì°¨ì›ì˜ ìœ„ì¹˜ë¥¼ ì§€ì •. ìŒìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ë’¤ì—ì„œë¶€í„° ì°¨ì›ì„ ê³„ì‚°.\n",
    "\n",
    "    >> ê²°ê³¼: ì§€ì •ëœ ìœ„ì¹˜ì— í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì´ ì¶”ê°€ëœ ìƒˆë¡œìš´ í…ì„œë¥¼ ë°˜í™˜.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7f00259",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1, 2, 3])   # shape: (3,)\n",
    "y = x.unsqueeze(dim=0)        # shape: (1, 3)\n",
    "z = x.unsqueeze(dim=1)        # shape: (3, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ccfe08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3])  # xì˜ shape: (3,)\n",
    "x_unsqueezed = x.unsqueeze(0)  # dim=0ì— ì°¨ì›ì„ ì¶”ê°€\n",
    "print(x_unsqueezed.shape)  # ì¶œë ¥: torch.Size([1, 3])\n",
    "\n",
    "x_unsqueezed = x.unsqueeze(1)  # dim=1ì— ì°¨ì›ì„ ì¶”ê°€\n",
    "print(x_unsqueezed.shape)  # ì¶œë ¥: torch.Size([3, 1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6e04895",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97293322",
   "metadata": {},
   "source": [
    "1. torch.from_numpy(data['x'].values)\n",
    "\n",
    "- data['x'].values: NumPy ë°°ì—´ í˜•íƒœì˜ ë°ì´í„°ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜.\n",
    "\n",
    "  > ì˜ˆë¥¼ ë“¤ì–´, data['x'].valuesì˜ í˜•íƒœê°€ (N,)ë¼ê³  ê°€ì •.\n",
    "\n",
    "2. .unsqueeze(dim=1)\n",
    "\n",
    "- dim=1ì— í¬ê¸°ê°€ 1ì¸ ì°¨ì›ì„ ì¶”ê°€.\n",
    "\n",
    "  > ê¸°ì¡´ í…ì„œì˜ shapeì´ (N,)ë¼ë©´, unsqueeze(dim=1)ì˜ ê²°ê³¼ëŠ” (N, 1).\n",
    "\n",
    "    >> ì´ ê³¼ì •ì€ ì¼ë°˜ì ìœ¼ë¡œ ë”¥ëŸ¬ë‹ ëª¨ë¸ì— ì…ë ¥ ë°ì´í„°ë¥¼ ë§ì¶”ê¸° ìœ„í•´ ì‚¬ìš©.\n",
    "\n",
    "    >> ì˜ˆ: ì…ë ¥ ë°ì´í„°ê°€ 2D í˜•íƒœì¸ (N, 1)ì´ ë˜ì–´ì•¼ í•˜ëŠ” ê²½ìš°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3634af",
   "metadata": {},
   "source": [
    "- ì™œ unsqueeze(dim=1)ì´ í•„ìš”í•œê°€?\n",
    "\n",
    "  > ë§ì€ ë”¥ëŸ¬ë‹ ëª¨ë¸ì€ 2D ì…ë ¥ì„ í•„ìš”\n",
    "  \n",
    "    >> ì„ í˜• íšŒê·€ë‚˜ MLP(Multi-Layer Perceptron) ê°™ì€ ëª¨ë¸ì—ì„œëŠ” ê° ì…ë ¥ ë°ì´í„°ê°€ (N, D) í˜•íƒœ(ì¦‰, Nê°œì˜ ìƒ˜í”Œì— ëŒ€í•´ Dì°¨ì› íŠ¹ì„± ë²¡í„°).\n",
    "\n",
    "    >> ì›ë˜ ë°ì´í„°ê°€ 1D í…ì„œ: [x1, x2, x3, ...] (shape: (N,)).\n",
    "\n",
    "    >> 2Dë¡œ ë³€ê²½: [[x1], [x2], [x3], ...] (shape: (N, 1)).\n",
    "\n",
    "    >> unsqueeze(dim=1)ì„ ì‚¬ìš©í•˜ì—¬ 2D í…ì„œë¡œ í™•ì¥.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9da8a8",
   "metadata": {},
   "source": [
    "- ì™œ 2D ì…ë ¥ì„ ì“°ëŠ”ê°€?\n",
    "\n",
    "  > ëŒ€ë¶€ë¶„ì˜ **ê¸°ë³¸ ì‹ ê²½ë§ ê³„ì¸µ(ì˜ˆ: nn.Linear)**ì€ ìˆ˜í•™ì ìœ¼ë¡œ **í–‰ë ¬ ê³±ì…ˆ (Matrix Multiplication)**ì„ ê¸°ë°˜ìœ¼ë¡œ ë™ì‘\n",
    "  \n",
    "    >> nn.Linear(in_features, out_features)ëŠ” ë‚´ë¶€ì  ê³„ì‚°:\n",
    "\n",
    "    Y=X.WT+b\n",
    "\n",
    "  > X: ì…ë ¥ ë°ì´í„°, shape = (N, in_features)\n",
    "\n",
    "  > W: ê°€ì¤‘ì¹˜, shape = (out_features, in_features)\n",
    "\n",
    "  > Y: ì¶œë ¥, shape = (N, out_features)\n",
    "\n",
    "- ì…ë ¥ì€ ë°˜ë“œì‹œ (ë°°ì¹˜ í¬ê¸° N, íŠ¹ì„± ê°œìˆ˜ F) í˜•íƒœ, ì¦‰ 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a205973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.1724, -0.3700], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1D ë²¡í„° ì…ë ¥ì¼ ë•Œ\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ìƒ˜í”Œ í•˜ë‚˜ì§œë¦¬ (íŠ¹ì§• 3ê°œ)\n",
    "x = torch.tensor([1.0, 2.0, 3.0])   # shape: (3,)\n",
    "\n",
    "layer = nn.Linear(3, 2)\n",
    "# ì˜¤ë¥˜ ë°œìƒ: 1D í…ì„œë¼ì„œ ë°°ì¹˜ ì°¨ì› ì—†ìŒ\n",
    "layer(x)\n",
    "# nn.LinearëŠ” (N, F) í˜•íƒœë¥¼ ê¸°ëŒ€í•˜ëŠ”ë°, (3,)ëŠ” ì°¨ì›ì´ í•˜ë‚˜ë¼ì„œ ì—ëŸ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08133408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "# 2Dë¡œ ë§ì·„ì„ ë•Œ\n",
    "x = torch.tensor([[1.0, 2.0, 3.0]])   # shape: (1, 3), ë°°ì¹˜=1\n",
    "layer = nn.Linear(3, 2)\n",
    "y = layer(x)\n",
    "print(y.shape)   # torch.Size([1, 2])\n",
    "# ì…ë ¥ì´ (N=1, F=3)ì´ë¯€ë¡œ ì •ìƒ ë™ì‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d0abb",
   "metadata": {},
   "source": [
    "- PyTorch ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤ì´ 2D ì…ë ¥ì„ ìš”êµ¬í•˜ëŠ” ì´ìœ \n",
    "\n",
    "  > í–‰ë ¬ ê³± ê¸°ë°˜ì˜ ì‹ ê²½ë§ ì—°ì‚°(Linear layer ë“±)ì´ (ë°°ì¹˜ í¬ê¸°, íŠ¹ì§• ìˆ˜) 2ì°¨ì› ì…ë ¥ì„ ì „ì œë¡œ ì„¤ê³„ë˜ì—ˆê¸° ë•Œë¬¸ì´ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401223d8",
   "metadata": {},
   "source": [
    "- covtype.csvëŠ” Covertype ë°ì´í„°ì…‹ìœ¼ë¡œ, ë¯¸êµ­ ì½œë¡œë¼ë„ì£¼ì˜ êµ­ë¦½ê³µì›ì˜ í† ì–‘ ë° ì‹ìƒ ìœ í˜•ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ í‘œì¤€ ë°ì´í„°ì…‹\n",
    "\n",
    "  > UCI ë¨¸ì‹ ëŸ¬ë‹ ì €ì¥ì†Œì— ê³µê°œë˜ì–´ ìˆìœ¼ë©°, CSV í˜•ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a041531",
   "metadata": {},
   "source": [
    "Custom datasetì„ ë§Œë“¤ì–´ì„œ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ZRkBKGQWuti",
   "metadata": {
    "id": "9ZRkBKGQWuti"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/covtype.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m       label=torch.tensor(\u001b[38;5;28mself\u001b[39m.label.iloc[idx,\u001b[32m3\u001b[39m]).int()\n\u001b[32m     16\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m sample, label\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m tensor_dataset=\u001b[43mCustomDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata/covtype.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m dataset=DataLoader(tensor_dataset,batch_size=\u001b[32m4\u001b[39m,shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mCustomDataset.__init__\u001b[39m\u001b[34m(self, csv_file)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,csv_file):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m   \u001b[38;5;28mself\u001b[39m.label=\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/covtype.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,csv_file):\n",
    "      self.label=pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.label)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "      sample=torch.tensor(self.label.iloc[idx,0:3]).int()\n",
    "      label=torch.tensor(self.label.iloc[idx,3]).int()\n",
    "      return sample, label\n",
    "\n",
    "tensor_dataset=CustomDataset('data/covtype.csv')\n",
    "dataset=DataLoader(tensor_dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6844928",
   "metadata": {},
   "source": [
    "- PyTorchì—ì„œ **DataLoader**ë¥¼ ì“°ëŠ” ì´ìœ \n",
    "\n",
    "  > ë”¥ëŸ¬ë‹ í•™ìŠµ ê³¼ì •ì— ë§ëŠ” íš¨ìœ¨ì ì¸ ë°ì´í„° ê³µê¸‰\n",
    "\n",
    "- DataLoaderì˜ í•µì‹¬ ì—­í• :\n",
    "\n",
    "  1) ë¯¸ë‹ˆë°°ì¹˜(batch) ë‹¨ìœ„ë¡œ ë°ì´í„° ì œê³µ\n",
    "\n",
    "    >> ë”¥ëŸ¬ë‹ í•™ìŠµì€ í•œ ë²ˆì— ëª¨ë“  ë°ì´í„°ë¥¼ ì“°ì§€ ì•Šê³ , ì‘ì€ ë©ì–´ë¦¬(mini-batch)ë¡œ ì˜ë¼ì„œ ë°˜ë³µ í•™ìŠµ\n",
    "\n",
    "    >> DataLoaderê°€ batch_sizeëŒ€ë¡œ ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ë‚˜ëˆ ì„œ ì œê³µ\n",
    "\n",
    "  2) ì…”í”Œ(shuffle)\n",
    "\n",
    "    >> í•™ìŠµí•  ë•Œ ë§¤ epochë§ˆë‹¤ ë°ì´í„° ìˆœì„œë¥¼ ì„ì–´ì£¼ëŠ” ê²Œ ì¤‘ìš”\n",
    "\n",
    "    >> DataLoaderëŠ” shuffle=True ì˜µì…˜ìœ¼ë¡œ ìë™ ì²˜ë¦¬\n",
    "\n",
    "  3) ë³‘ë ¬ ë°ì´í„° ë¡œë”© (multiprocessing)\n",
    "\n",
    "    >> í° ë°ì´í„°ì…‹ì¼ìˆ˜ë¡ ë§¤ë²ˆ __getitem__() í˜¸ì¶œ ì‹œ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦°ë‹¤.\n",
    "\n",
    "    >> num_workers ì˜µì…˜ì„ ì£¼ë©´ ì—¬ëŸ¬ í”„ë¡œì„¸ìŠ¤ê°€ ë™ì‹œì— ë°ì´í„°ë¥¼ ì½ì–´ì„œ GPU ì—°ì‚°ì´ ë†€ì§€ ì•Šë„ë¡ CPUê°€ ë¯¸ë¦¬ ì¤€ë¹„.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b0bf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: inputs=[17.0, 11.0, 6.0, 13.0], targets=[34.0, 22.0, 12.0, 26.0]\n",
      "Batch 1: inputs=[8.0, 5.0, 3.0, 16.0], targets=[16.0, 10.0, 6.0, 32.0]\n",
      "Batch 2: inputs=[0.0, 12.0, 18.0, 1.0], targets=[0.0, 24.0, 36.0, 2.0]\n",
      "Batch 3: inputs=[19.0, 15.0, 4.0, 9.0], targets=[38.0, 30.0, 8.0, 18.0]\n",
      "Batch 4: inputs=[7.0, 10.0, 2.0, 14.0], targets=[14.0, 20.0, 4.0, 28.0]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ê°€ì§œ ë°ì´í„°ì…‹\n",
    "x = torch.arange(20).float().unsqueeze(1)   # shape (20,1)\n",
    "y = x * 2                                   # ë ˆì´ë¸”\n",
    "\n",
    "dataset = TensorDataset(x, y)\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„ì—ì„œ ì‚¬ìš©\n",
    "for batch_idx, (inputs, targets) in enumerate(loader):\n",
    "    print(f\"Batch {batch_idx}: inputs={inputs.squeeze().tolist()}, targets={targets.squeeze().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe737f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4b1102b",
   "metadata": {},
   "source": [
    "### PyTorchì˜ DataLoaderëŠ” ë¯¸ë‹ˆë°°ì¹˜, ì…”í”Œ, ë³‘ë ¬ ë°ì´í„° ë¡œë”©ì„ ìë™í™”í•´ì„œ ëª¨ë¸ í•™ìŠµì„ ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ì§„í–‰í•˜ê²Œ ë„ì™€ì£¼ëŠ” í•µì‹¬ ë„êµ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3a20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ì‹¤í–‰ ê¸ˆì§€!!! - êµ‰ì¥íˆ ì˜¤ë˜ ê±¸ë¦°ë‹¤ \n",
    "# dataloaderëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë°˜ë³µì‹¤í–‰í•˜ëŠ” ê¸°ëŠ¥ => ì‹¤í–‰ì‹œí‚¤ì§€ ì•Šì•„ì•¼ í•¨\n",
    "for i,data in enumerate(dataset,0):\n",
    "    print(i,end='')\n",
    "    batch=data[0]\n",
    "    print(batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6aaf0",
   "metadata": {},
   "source": [
    "íŒŒì´í† ì¹˜ì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ì…‹ ì‚¬ìš©(48í˜ì´ì§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "rUmwfd6_kvCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5807,
     "status": "ok",
     "timestamp": 1715773231058,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "rUmwfd6_kvCq",
    "outputId": "a582e146-cbd9-4a28-953a-3b05499a9b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì´í† ì¹˜ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ìœ¼ë ¤ë©´ requests ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜\n",
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c354b9",
   "metadata": {},
   "source": [
    "- í† ì¹˜ë¹„ì „: íŒŒì´í† ì¹˜ì—ì„œ ì œê³µí•˜ëŠ” ë°ì´í„°ì„¸íŠ¸ë“¤ì´ ëª¨ì—¬ ìˆëŠ” íŒ¨í‚¤ì§€\n",
    "\n",
    "  > MNIST, ImageBet ë“±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7423e510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (2.8.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (2.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torchvision-0.23.0-cp313-cp313-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/1.6 MB 25.8 MB/s eta 0:00:00\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip3 uninstall torch torchvision\n",
    "!pip3 install torch torchvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a99daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "0.23.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(torch.__version__)         # PyTorch ë²„ì „ ì¶œë ¥\n",
    "print(torchvision.__version__)   # torchvision ë²„ì „ ì¶œë ¥\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "V6n5xvrSk7m6",
   "metadata": {
    "id": "V6n5xvrSk7m6"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(1.0,))\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fTpwWvg5liXj",
   "metadata": {
    "id": "fTpwWvg5liXj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "import requests\n",
    "download_root = '/chap02/data/MNIST_DATASET'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KD-uI2jmm-Vo",
   "metadata": {
    "id": "KD-uI2jmm-Vo"
   },
   "source": [
    "2.2.3 ëª¨ë¸ ì •ì˜\n",
    "\n",
    "- íŒŒì´í† ì¹˜ì—ì„œ ëª¨ë¸ ì •ì˜: ëª¨ë“ˆì„ ìƒì†í•œ í´ë˜ìŠ¤ë¥¼ ì‚¬ìš©\n",
    "\n",
    "  > ê³„ì¸µ: í•©ì„±ê³±ì¸µ, ì„ í˜• ê³„ì¸µ(linear layer)\n",
    "\n",
    "  > ëª¨ë“ˆ: í•œ ê°œ ì´ìƒì˜ ê³„ì¸µì´ ëª¨ì—¬ì„œ ëª¨ë“ˆ êµ¬ì„± > í´ë˜ìŠ¤ë¡œ ì •ì˜\n",
    "\n",
    "  > ëª¨ë¸: í•œê°œì˜ ëª¨ë“ˆì´ ëª¨ë¸ì´ ëœë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c69344",
   "metadata": {},
   "source": [
    "#### ë‹¨ìˆœ ì‹ ê²½ë§ ì •ì˜í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "- nn.Moduleì„ ìƒì†ë°›ì§€ ì•Šê³  ê³„ì¸µìœ¼ë¡œ ëª¨ë¸ì„ ë§Œë“¤ ë•Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1EZYoRRPmylO",
   "metadata": {
    "id": "1EZYoRRPmylO"
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "model = nn.Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e711eca3",
   "metadata": {},
   "source": [
    "#### nn.Module()ì„ ìƒì†í•˜ì—¬ ì •ì˜í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "- PyTorchì—ì„œ nn.Moduleì„ ìƒì†ë°›ì•„ ì‚¬ìš©ì ì •ì˜ ì‹ ê²½ë§(ëª¨ë¸)ì„ ë§Œë“œëŠ” ì „í˜•ì ì¸ ë°©ì‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9e1ab636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):                    # â‘  nn.Moduleì„ ìƒì†\n",
    "  def __init__(self, inputs): # ëª¨ë¸ì— í¬í•¨ë  **ë ˆì´ì–´(layer)**ì™€ **ì—°ì‚°(activation function)**ì„ ì •ì˜.\n",
    "    super(MLP, self).__init__()          # â‘¡ ë¶€ëª¨ í´ë˜ìŠ¤ ì´ˆê¸°í™”\n",
    "    self.layer = nn.Linear(inputs, 1)    # â‘¢ ì„ í˜•ì¸µ (ì…ë ¥ â†’ ì¶œë ¥ 1ê°œ)\n",
    "    self.activation = nn.Sigmoid()       # â‘£ ì‹œê·¸ëª¨ì´ë“œ í™œì„±í™” í•¨ìˆ˜\n",
    "  \n",
    "# ëª¨ë¸ì˜ ìˆœì „íŒŒ(forward pass) ê³¼ì • ì •ì˜\n",
    "# í•™ìŠµì´ë‚˜ ì¶”ë¡  ì‹œ model(X)ë¥¼ í˜¸ì¶œí•˜ë©´ ë‚´ë¶€ì ìœ¼ë¡œ forward()ê°€ ì‹¤í–‰ > __call__()\n",
    "  def forward(self, X):                  # â‘¤ forward() ì˜¤ë²„ë¼ì´ë“œ\n",
    "    X = self.layer(X)                    # (N, inputs) â†’ (N, 1)\n",
    "    X = self.activation(X)               # 0~1 ì‚¬ì´ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91d2f9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6281],\n",
      "        [0.6787]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# ì…ë ¥ íŠ¹ì„± 3ê°œì§œë¦¬ MLP ìƒì„±\n",
    "model = MLP(inputs=3)\n",
    "\n",
    "# ë”ë¯¸ ë°ì´í„°\n",
    "x = torch.tensor([[0.1, 0.2, 0.3],\n",
    "                  [0.4, 0.5, 0.6]])\n",
    "\n",
    "# ìˆœì „íŒŒ ì‹¤í–‰\n",
    "y = model(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0690a8",
   "metadata": {},
   "source": [
    "- torch.nn.Moduleì€ PyTorchì—ì„œ ì‹ ê²½ë§ ëª¨ë¸ì„ ì •ì˜í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤\n",
    "\n",
    "  > ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ê³ , ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•  ë•Œ í•„ìš”í•œ ë©”ì†Œë“œë¥¼ ì œê³µ\n",
    "  \n",
    "  > forward() ë©”ì†Œë“œëŠ” ëª¨ë¸ì˜ ì „ë°©í–¥ íŒ¨ìŠ¤(forward pass) ë¥¼ ì •ì˜í•˜ëŠ” ë° ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "Q39CVdKV2DRE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1715773256089,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Q39CVdKV2DRE",
    "outputId": "b69d5165-01d3-422e-9821-356a240faf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0053, 0.0000, 0.0000, 0.2153, 0.1402, 0.0000, 0.0000, 0.0000, 0.3635,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1343, 0.0440, 0.0000, 0.0000, 0.0000, 0.1593,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2405, 0.1023, 0.0000, 0.0000, 0.0000, 0.0986,\n",
      "         0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = x.view(x.shape[0],-1)\n",
    "    x = self.layer3(x)\n",
    "    return x\n",
    "\n",
    "model = MLP()\n",
    "data = torch.randn(3, 3, 32, 32)  # 3ê°œì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ê° ì´ë¯¸ì§€ëŠ” 3ì±„ë„(RGB)ì´ë©°, í¬ê¸°ëŠ” 32x32ì…ë‹ˆë‹¤.\n",
    "model = MLP()  # ì…ë ¥ì˜ ì°¨ì›ì„ ë°ì´í„°ì˜ ê¸¸ì´ë¡œ\n",
    "output = model(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec339731",
   "metadata": {},
   "source": [
    "- forward() ë©”ì†Œë“œë¥¼ ì •ì˜\n",
    "\n",
    "  > ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” ê²ƒë§Œìœ¼ë¡œ ì´ ë©”ì†Œë“œê°€ ìë™ìœ¼ë¡œ ì‹¤í–‰\n",
    "  \n",
    "    >> model(x)ì™€ ê°™ì´ í˜¸ì¶œí•˜ë©´ forward() ë©”ì†Œë“œê°€ ì‹¤í–‰.\n",
    "\n",
    "- nn.Module í´ë˜ìŠ¤ëŠ” PyTorchì—ì„œ ì‹ ê²½ë§ ëª¨ë¸ì„ ì •ì˜í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ê¸°ë³¸ í´ë˜ìŠ¤\n",
    "\n",
    "  > ì´ í´ë˜ìŠ¤ëŠ” ëª¨ë¸ì˜ êµ¬ì¡°(Layer ì •ì˜)ì™€ ë™ì‘(Forward Pass)ì„ ì •ì˜í•  ìˆ˜ ìˆëŠ” ë©”ì†Œë“œë“¤ì„ ì œê³µ\n",
    "  \n",
    "  > model(input_data)ë¼ê³  í˜¸ì¶œí•  ë•Œ, PyTorchëŠ” ìë™ìœ¼ë¡œ forward() ë©”ì†Œë“œë¥¼ ì‹¤í–‰\n",
    "  \n",
    "    >> output = model(input_data)\n",
    "\n",
    "    >> ëª¨ë¸ì„ í˜¸ì¶œí•˜ëŠ” model(input_data)ëŠ” __call__() ë©”ì†Œë“œë¥¼ íŠ¸ë¦¬ê±°.\n",
    "\n",
    "    >> nn.Moduleì€ __call__() ë©”ì†Œë“œë¥¼ ì˜¤ë²„ë¼ì´ë“œ(ì¬ì •ì˜)í•œ í´ë˜ìŠ¤.\n",
    "    \n",
    "       ì´ ë©”ì†Œë“œëŠ” ì‹¤ì œë¡œ forward() ë©”ì†Œë“œë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "  > nn.Module.__call__(self, *input, **kwargs):\n",
    "\n",
    "    >> forward() ë©”ì†Œë“œ í˜¸ì¶œ: __call__()ëŠ” ì¸ìŠ¤í„´ìŠ¤ê°€ í˜¸ì¶œë  ë•Œ, ë‚´ë¶€ì ìœ¼ë¡œ forward() ë©”ì†Œë“œë¥¼ í˜¸ì¶œ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a924160b",
   "metadata": {},
   "source": [
    "#### í•¨ìˆ˜ë¡œ ì‹ ê²½ë§ì„ ì •ì˜í•˜ëŠ” ë°©ë²•\n",
    "\n",
    "- ë³€ìˆ˜ë¡œ ì €ì¥í•œ ê³„ì¸µì„ ì‚¬ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4w8Llw5iFWMR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1715773262923,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4w8Llw5iFWMR",
    "outputId": "24a8507a-8e6f-46bc-8ce6-6639136a09ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[ 0.0725],\n",
      "        [ 0.1882],\n",
      "        [ 0.2699],\n",
      "        [-0.0889],\n",
      "        [ 0.3176],\n",
      "        [ 0.2531],\n",
      "        [-0.1122],\n",
      "        [ 0.2612],\n",
      "        [ 0.2465],\n",
      "        [ 0.1523]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output) # nn.Sequentialë„ nn.Moduleì„ ìƒì†ë°›ì€ í´ë˜ìŠ¤\n",
    "    return net\n",
    "\n",
    "# ë°ì´í„° ì¤€ë¹„\n",
    "data = torch.randn(10, 1)  # ì˜ˆì‹œë¡œ 10ê°œì˜ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "print(data.shape)\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "model = MLP()\n",
    "# model(data) í˜¸ì¶œ ì‹œ ë‚´ë¶€ì ìœ¼ë¡œ __call__ â†’ forward() ì‹¤í–‰ êµ¬ì¡°ë¥¼ ë”°ë¥¸ë‹¤.\n",
    "# nn.Sequentialì€ forward()ì—ì„œ ì•ˆì— ë„£ì€ ë ˆì´ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©\n",
    "\n",
    "# ëª¨ë¸ í˜¸ì¶œ\n",
    "output = model(data) #data.shape = (10,1)ì´ë¯€ë¡œ in_featuresëŠ” 10ì´ ë˜ê³  10ê°œì˜ ì…ë ¥ì„ ë°›ì•„ë“¤ì„\n",
    "#  model(data)ë¥¼ í˜¸ì¶œí•˜ë©´, MLP í´ë˜ìŠ¤ì˜ forward ë©”ì„œë“œê°€ í˜¸ì¶œë˜ë©´ì„œ\n",
    "##ì…ë ¥ ë°ì´í„°ê°€ ì „ë‹¬ë˜ê³ , í•´ë‹¹ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•œ ì—°ì‚°ì´ ìˆ˜í–‰ë˜ì–´ ì¶œë ¥ì´ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NKD_8M96Qxp4",
   "metadata": {
    "id": "NKD_8M96Qxp4"
   },
   "source": [
    "#### 2.2.4 ëª¨ë¸ íŒŒë¼ë¯¸í„° ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "Fg5TyyvBQ2Zt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "error",
     "timestamp": 1715773784970,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Fg5TyyvBQ2Zt",
    "outputId": "7c50a3e6-e570-4d80-f70d-45cf122fdb77"
   },
   "outputs": [],
   "source": [
    "### êµì¬ 56í˜ì´ì§€: ëª¨ë¸ íŒŒë¼ë¯¸í„° ì½”ë“œ\n",
    "from torch.optim import optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                              lr_lambda=lambda epoch: 0.95**epoch)\n",
    "batch_size = 32\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(1, 100+1):\n",
    "    model.train()\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x) # ì¶œë ¥ ê³„ì‚° \n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward() # ì—­ì „íŒŒ í•™ìŠµ\n",
    "        optimizer.step() # ê¸°ìš¸ê¸° ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51b529",
   "metadata": {},
   "source": [
    "#### 2.2.5 ëª¨ë¸ í›ˆë ¨ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "GZ8ZUtIkSr6o",
   "metadata": {
    "id": "GZ8ZUtIkSr6o"
   },
   "outputs": [],
   "source": [
    "from torch.optim import optimizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ë°ì´í„°ì…‹ê³¼ ë°ì´í„°ë¡œë”ë¥¼ ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì˜ˆë¥¼ ë“¤ì–´, ë‹¨ìˆœí•œ ë°ì´í„°ì…‹ì„ ë§Œë“¤ê³  ë°ì´í„°ë¡œë”ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# ì˜ˆì œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "data = [(torch.randn(1), torch.randn(1)) for _ in range(100)]\n",
    "# ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "dataset = SimpleDataset(data)\n",
    "# ë°ì´í„°ë¡œë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net\n",
    "\n",
    "# ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "model = MLP()\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95**epoch)\n",
    "\n",
    "# ëª¨ë¸ í›ˆë ¨ êµì¬ 57í˜ì´ì§€\n",
    "for epoch in range(1, 100+1):\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "# í•™ìŠµ í›„ì˜ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uX4zgvP4S-tG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1715845783636,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "uX4zgvP4S-tG",
    "outputId": "295f3bfd-97fc-4479-ba50-816465385334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([0.5705]), tensor([1.2116])), (tensor([0.1113]), tensor([-0.7853])), (tensor([-0.3382]), tensor([-1.3136])), (tensor([-0.2250]), tensor([-1.1769])), (tensor([0.3211]), tensor([0.0980])), (tensor([0.0604]), tensor([-0.6976])), (tensor([-0.4376]), tensor([0.1561])), (tensor([-2.8135]), tensor([-1.6216])), (tensor([-0.4019]), tensor([0.5546])), (tensor([-0.4785]), tensor([-0.4872]))]\n",
      "Input: tensor([0.5705])\n",
      "Actual Output: tensor([1.2116])\n",
      "Predicted Output: tensor([-0.1021])\n",
      "Input: tensor([0.1113])\n",
      "Actual Output: tensor([-0.7853])\n",
      "Predicted Output: tensor([-0.0411])\n",
      "Input: tensor([-0.3382])\n",
      "Actual Output: tensor([-1.3136])\n",
      "Predicted Output: tensor([0.0360])\n",
      "Input: tensor([-0.2250])\n",
      "Actual Output: tensor([-1.1769])\n",
      "Predicted Output: tensor([0.0127])\n",
      "Input: tensor([0.3211])\n",
      "Actual Output: tensor([0.0980])\n",
      "Predicted Output: tensor([-0.0647])\n",
      "Input: tensor([0.0604])\n",
      "Actual Output: tensor([-0.6976])\n",
      "Predicted Output: tensor([-0.0354])\n",
      "Input: tensor([-0.4376])\n",
      "Actual Output: tensor([0.1561])\n",
      "Predicted Output: tensor([0.0542])\n",
      "Input: tensor([-2.8135])\n",
      "Actual Output: tensor([-1.6216])\n",
      "Predicted Output: tensor([0.3096])\n",
      "Input: tensor([-0.4019])\n",
      "Actual Output: tensor([0.5546])\n",
      "Predicted Output: tensor([0.0491])\n",
      "Input: tensor([-0.4785])\n",
      "Actual Output: tensor([-0.4872])\n",
      "Predicted Output: tensor([0.0593])\n"
     ]
    }
   ],
   "source": [
    "# ì˜ˆì¸¡ì„ ìˆ˜í–‰í•  í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "test_data = [(torch.randn(1), torch.randn(1)) for _ in range(10)]\n",
    "print(test_data)\n",
    "# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "model.eval()\n",
    "\n",
    "# ê° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "with torch.no_grad():  # ê·¸ë¼ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™”\n",
    "    for x_test, y_test in test_data:\n",
    "        # ì…ë ¥ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ì „ë‹¬í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "        predicted_output = model(x_test)\n",
    "        print(\"Input:\", x_test)\n",
    "        print(\"Actual Output:\", y_test)\n",
    "        print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_-u-7Gt_UBIe",
   "metadata": {
    "id": "_-u-7Gt_UBIe"
   },
   "source": [
    "#### 2.2.6 ëª¨ë¸í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ARr32BLLUD1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122670,
     "status": "ok",
     "timestamp": 1715744174721,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "ARr32BLLUD1a",
    "outputId": "307bff9a-a067-46ce-eaa1-cb0bde4ca220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchmetrics\n",
      "  Downloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
      "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
      "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Collecting pretty-errors==1.2.25 (from torchmetrics)\n",
      "  Downloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
      "Collecting colorama (from pretty-errors==1.2.25->torchmetrics)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.14.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
      "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, colorama, pretty-errors, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics\n",
      "Successfully installed colorama-0.4.6 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pretty-errors-1.2.25 torchmetrics-1.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XWl_6kAhUK3z",
   "metadata": {
    "id": "XWl_6kAhUK3z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "preds = torch.randn(10,5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "num_classes = preds.size(1)  # preds í…ì„œì˜ ë§ˆì§€ë§‰ ì°¨ì›ì˜ í¬ê¸°ë¥¼ ê°€ì ¸ì˜´\n",
    "#acc = torchmetrics.functional.accuracy(preds, target)\n",
    "acc = torchmetrics.functional.accuracy(preds, target, task=\"MULTICLASS\", num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CnGTKD6DUyUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1715745027026,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "CnGTKD6DUyUF",
    "outputId": "49a104dd-b171-4d49-b9be-6ead0f8ddbe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on batch 0: 0.30000001192092896\n",
      "Accuracy on batch 1: 0.30000001192092896\n",
      "Accuracy on batch 2: 0.10000000149011612\n",
      "Accuracy on batch 3: 0.30000001192092896\n",
      "Accuracy on batch 4: 0.10000000149011612\n",
      "Accuracy on batch 5: 0.10000000149011612\n",
      "Accuracy on batch 6: 0.10000000149011612\n",
      "Accuracy on batch 7: 0.20000000298023224\n",
      "Accuracy on batch 8: 0.0\n",
      "Accuracy on batch 9: 0.10000000149011612\n",
      "Accuracy on all data 0.1599999964237213\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "num_classes = 5\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "#metric = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "\n",
    "n_batches = 10\n",
    "for i in range(n_batches):\n",
    "    preds = torch.randn(10,5).softmax(dim=-1)\n",
    "    target = torch.randint(5, (10,))\n",
    "\n",
    "    acc = metric(preds, target)\n",
    "    print(f\"Accuracy on batch {i}: {acc}\")\n",
    "\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aS450QIM714i",
   "metadata": {
    "id": "aS450QIM714i"
   },
   "source": [
    "#### 2.2.7 í›ˆë ¨ê³¼ì • ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "- í…ì„œë³´ë“œë¥¼ ì‚¬ìš©í•œ ëª¨ë‹ˆí„°ë§\n",
    "\n",
    "  > í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” íŒŒë¼ë¯¸í„° ê°’ì´ ë³€í™” ë‚´ìš©ì„ ì‹œê°í™”\n",
    "\n",
    "  > ì„±ëŠ¥ì„ ì¶”ì , í‰ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mOuZaGIL7412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12547,
     "status": "ok",
     "timestamp": 1715771278437,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "mOuZaGIL7412",
    "outputId": "62ea6da7-52ce-4d03-ef13-017b9ebdc8d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.15.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.63.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.27.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.25.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.31.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (67.7.2)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kNJCuYN78JSd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "error",
     "timestamp": 1715772152456,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kNJCuYN78JSd",
    "outputId": "a8ae6cd1-b3f2-467b-cda5-ed9d5cf86bd8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6997dc9e1cf>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"/content/drive/MyDrive/Colab Notebooks/á„‘á…¡á„‹á…µá„á…©á„á…µ/pytorch2023/chap02/tensorboard\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_loss = 0.0\n",
    "\n",
    "    for i, (x,y) in enumerate(dataloader):\n",
    "        x,y = x.to(device).float(), y.to(device).float()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        writer.add_scalaer(\"Loss\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "writer.cloase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e98bca",
   "metadata": {
    "id": "42e98bca"
   },
   "outputs": [],
   "source": [
    "#### 2.4 íŒŒì´í† ì¹˜ ì½”ë“œ ë§›ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44961535",
   "metadata": {
    "id": "44961535"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb364a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "executionInfo": {
     "elapsed": 33709,
     "status": "ok",
     "timestamp": 1715847823458,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4fb364a0",
    "outputId": "e33dc709-5903-4240-96d5-6aa52bfe8bfa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-b3a6bee2-1625-4c38-8126-2a5f5754deac\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-b3a6bee2-1625-4c38-8126-2a5f5754deac\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving car_evaluation.csv to car_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/car_evaluation.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ea085b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1715847857445,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "63ea085b",
    "outputId": "25949609-9d33-4b31-b5a0-e1f64c6a88f5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 1728,\n  \"fields\": [\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"high\",\n          \"low\",\n          \"vhigh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"maint\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"high\",\n          \"low\",\n          \"vhigh\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doors\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"3\",\n          \"5more\",\n          \"2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"persons\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"2\",\n          \"4\",\n          \"more\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lug_capacity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"small\",\n          \"med\",\n          \"big\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"safety\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"low\",\n          \"med\",\n          \"high\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"output\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"acc\",\n          \"good\",\n          \"unacc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "dataset"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_capacity</th>\n",
       "      <th>safety</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-ae4e8bd1-43cc-44f3-83d0-dcb687b78c31');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-cff4453a-1cf2-46e6-b353-61de473fb23d\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cff4453a-1cf2-46e6-b353-61de473fb23d')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-cff4453a-1cf2-46e6-b353-61de473fb23d button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   price  maint doors persons lug_capacity safety output\n",
       "0  vhigh  vhigh     2       2        small    low  unacc\n",
       "1  vhigh  vhigh     2       2        small    med  unacc\n",
       "2  vhigh  vhigh     2       2        small   high  unacc\n",
       "3  vhigh  vhigh     2       2          med    low  unacc\n",
       "4  vhigh  vhigh     2       2          med    med  unacc"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b271bd",
   "metadata": {},
   "source": [
    "- ì„ë² ë”©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854b091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1715847866514,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "1854b091",
    "outputId": "35e2b6be-5ad5-4b18-a5df-c3c1e7cbd261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 6\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "dataset.output.value_counts().plot(kind='pie', autopct='%0.05f%%', colors=['lightblue', 'lightgreen', 'orange', 'pink'], explode=(0.05, 0.05, 0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c82b06",
   "metadata": {
    "id": "73c82b06"
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fc4df",
   "metadata": {
    "id": "281fc4df"
   },
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    dataset[category] = dataset[category].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575b6ee",
   "metadata": {},
   "source": [
    "- ë²”ì£¼í˜• ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜\n",
    "\n",
    "  > ë²”ì£¼í˜• ë°ì´í„° > dataset[ategory] > ë„˜íŒŒì´ ë°°ì—´ > í…ì„œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4443b",
   "metadata": {},
   "source": [
    "ë„˜íŒŒì´ ê°ì²´ë¥¼ í•©ì¹  ë•Œ np.stack, np.concatenate\n",
    "\n",
    "- np.concatenate()\n",
    "\n",
    "  > ê¸°ì¡´ ì°¨ì›ì„ ë”°ë¼ ì´ì–´ë¶™ì„\n",
    "\n",
    "  > ìƒˆë¡œìš´ ì°¨ì›ì€ ìƒê¸°ì§€ ì•ŠìŒ\n",
    "\n",
    "    >> ë¶™ì´ëŠ” ì¶•(axis)ì˜ í¬ê¸°ê°€ ë§ì•„ì•¼ í•œë‹¤.\n",
    "\n",
    "- np.stack()\n",
    "\n",
    "  > ìƒˆë¡œìš´ ì°¨ì›ì„ ì¶”ê°€í•œ ë’¤ ê·¸ ì¶•ì„ ë”°ë¼ ìŒ“ìŒ\n",
    "\n",
    "  > ë°°ì—´ì˜ ì°¨ì›ì´ 1 ëŠ˜ì–´ë‚¨\n",
    "\n",
    "  > ëª¨ë“  ë°°ì—´ì˜ shapeì´ ë™ì¼í•´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43feb42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2],\n",
    "              [3, 4]])   # shape (2,2)\n",
    "\n",
    "b = np.array([[5, 6],\n",
    "              [7, 8]])   # shape (2,2)\n",
    "\n",
    "# axis=0 â†’ í–‰ ë°©í–¥ìœ¼ë¡œ ë¶™ì´ê¸°\n",
    "c0 = np.concatenate([a, b], axis=0)\n",
    "# [[1, 2],\n",
    "#  [3, 4],\n",
    "#  [5, 6],\n",
    "#  [7, 8]]\n",
    "print(c0.shape)  # (4,2)\n",
    "\n",
    "# axis=1 â†’ ì—´ ë°©í–¥ìœ¼ë¡œ ë¶™ì´ê¸°\n",
    "c1 = np.concatenate([a, b], axis=1)\n",
    "# [[1, 2, 5, 6],\n",
    "#  [3, 4, 7, 8]]\n",
    "print(c1.shape)  # (2,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a27b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2],\n",
    "              [3, 4]])   # shape (2,2)\n",
    "\n",
    "b = np.array([[5, 6],\n",
    "              [7, 8]])   # shape (2,2)\n",
    "\n",
    "# axis=0 â†’ ìƒˆ ì°¨ì›(0ë²ˆ ì¶•)ì„ ë§Œë“¤ê³  ê·¸ ë°©í–¥ìœ¼ë¡œ ìŒ“ê¸°\n",
    "s0 = np.stack([a, b], axis=0)\n",
    "# [[[1, 2],\n",
    "#   [3, 4]],\n",
    "#\n",
    "#  [[5, 6],\n",
    "#   [7, 8]]]\n",
    "print(s0.shape)  # (2,2,2)\n",
    "\n",
    "# axis=1 â†’ ìƒˆ ì°¨ì›(1ë²ˆ ì¶•)ì— ìŒ“ê¸°\n",
    "s1 = np.stack([a, b], axis=1) # í–‰ë§ˆë‹¤ ë‚˜ë€íˆ \"ì˜†ì—\" ë¶™ì„ >  í–‰ ë‹¨ìœ„ë¡œ ë‚˜ë€íˆ ìŒ“ê¸°\n",
    "# í–‰(row)ë§ˆë‹¤ aì™€ bë¥¼ ê°™ì€ ìœ„ì¹˜ì— ë¼ì›Œì„œ ìƒˆë¡œìš´ ì¶•ìœ¼ë¡œ ë¬¶ëŠ”ë‹¤\n",
    "# [[[1, 2],\n",
    "#   [5, 6]],\n",
    "#\n",
    "#  [[3, 4],\n",
    "#   [7, 8]]]\n",
    "print(s1.shape)  # (2,2,2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c85467",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "b = np.array([[5,6],[7,8]])\n",
    "c = np.array([[5,6],[7,8],[9,10]])\n",
    "\n",
    "print(np.concatenate(a,b), axis=0)\n",
    "print('---')\n",
    "print(np.stack(a,b), axis=0)\n",
    "print('++++')\n",
    "print(np.concatenate(a,b), axis=1)\n",
    "print('---')\n",
    "print(np.stack(a,b), axis=1) # 74í˜ì´ì§€ ê·¸ë¦¼ 2-29 ê²°ê³¼ì™€ ë¹„êµ í™•ì¸ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b735e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1715848096716,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "c6b735e5",
    "outputId": "f41449be-1574-466a-c17a-ee45dd5828d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 0, 2, 1],\n",
       "       [3, 3, 0, 0, 2, 2],\n",
       "       [3, 3, 0, 0, 2, 0],\n",
       "       [3, 3, 0, 0, 1, 1],\n",
       "       [3, 3, 0, 0, 1, 2],\n",
       "       [3, 3, 0, 0, 1, 0],\n",
       "       [3, 3, 0, 0, 0, 1],\n",
       "       [3, 3, 0, 0, 0, 2],\n",
       "       [3, 3, 0, 0, 0, 0],\n",
       "       [3, 3, 0, 1, 2, 1]], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = dataset['price'].cat.codes.values # ë„˜íŒŒì´ ë°°ì—´ë¡œ ë³€í™˜ \n",
    "maint = dataset['maint'].cat.codes.values\n",
    "doors = dataset['doors'].cat.codes.values\n",
    "persons = dataset['persons'].cat.codes.values\n",
    "lug_capacity = dataset['lug_capacity'].cat.codes.values\n",
    "safety = dataset['safety'].cat.codes.values\n",
    "\n",
    "categorical_data = np.stack([price, maint, doors, persons, lug_capacity, safety], 1)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ea6d73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1715848214116,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "11ea6d73",
    "outputId": "c797995e-fdbf-421f-9930-8763c919ab0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 0, 0, 2, 1],\n",
       "        [3, 3, 0, 0, 2, 2],\n",
       "        [3, 3, 0, 0, 2, 0],\n",
       "        [3, 3, 0, 0, 1, 1],\n",
       "        [3, 3, 0, 0, 1, 2],\n",
       "        [3, 3, 0, 0, 1, 0],\n",
       "        [3, 3, 0, 0, 0, 1],\n",
       "        [3, 3, 0, 0, 0, 2],\n",
       "        [3, 3, 0, 0, 0, 0],\n",
       "        [3, 3, 0, 1, 2, 1]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì½”ë“œ 2-5 : ë°°ì—´ì„ í…ì„œë¡œ ë³€í™˜ \n",
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.DataFrame({\n",
    "    \"output\": [\"cat\", \"dog\", \"dog\", \"bird\", \"cat\"]\n",
    "})\n",
    "\n",
    "outputs = pd.get_dummies(dataset.output)\n",
    "print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e765bcab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1715848236754,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "e765bcab",
    "outputId": "eec174b9-b68c-4edd-af44-43cf89394ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 6])\n",
      "torch.Size([6912])\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ 2-6: ë ˆì´ë¸”ì„ ê°€ë³€ìˆ˜ë¡œ ë³€í™˜  > ë²”ì£¼í˜• ê°’ì„ ìˆ«ìë¡œ ë³€í™˜ \n",
    "outputs = pd.get_dummies(dataset.output) # íŒë‹¤ìŠ¤ì˜ ì›-í•« ì¸ì½”ë”©(one-hot encoding)\n",
    "outputs = outputs.values\n",
    "outputs = torch.tensor(outputs).flatten() # 77í˜ì´ì§€ ë°•ìŠ¤ ì„¤ëª… \n",
    "print(categorical_data.shape)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8f767a",
   "metadata": {},
   "source": [
    "- ravel(), reshape(), flatten(): 77í˜ì´ì§€ ë°•ìŠ¤\n",
    "\n",
    "1. ravel()\n",
    "\n",
    "  > ë°°ì—´ì„ **1ì°¨ì›ìœ¼ë¡œ í´ì„œ view(ì›ë³¸ ì°¸ì¡°)**ë¥¼ ë°˜í™˜.\n",
    "\n",
    "    >>ì›ë³¸ ë°ì´í„°ë¥¼ ê³µìœ í•˜ê¸° ë•Œë¬¸ì— ìˆ˜ì •í•˜ë©´ ì›ë³¸ë„ ë°”ë€” ìˆ˜ ìˆìŒ.\n",
    "\n",
    "2. flatten()\n",
    "\n",
    "  > ë°°ì—´ì„ **ë¬´ì¡°ê±´ 1ì°¨ì›ìœ¼ë¡œ í´ì„œ ë³µì‚¬ë³¸(copy)**ì„ ë§Œë“ ë‹¤.\n",
    "\n",
    "    >> ê²°ê³¼ë¥¼ ë°”ê¿”ë„ ì›ë³¸ì—ëŠ” ì˜í–¥ ì—†ìŒ\n",
    "\n",
    "3. reshape()\n",
    "\n",
    "  > ë°°ì—´ì„ ì§€ì •í•œ ëª¨ì–‘ìœ¼ë¡œ **ìƒˆë¡œ ë³´ê¸°(view) ë˜ëŠ” ë³µì‚¬ë³¸(copy)**ìœ¼ë¡œ ë°˜í™˜.\n",
    "\n",
    "    >> -1ì„ ë„£ìœ¼ë©´ ìë™ ê³„ì‚°í•´ì„œ í´ì¤Œ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c18312",
   "metadata": {},
   "source": [
    "#### ë²”ì£¼í˜• ë³€ìˆ˜(categorical variable) ì„ë² ë”©ì„ ë§Œë“œëŠ” ê³¼ì •\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e0711",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1715779105896,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "828e0711",
    "outputId": "ae0b1728-a854-430a-ab0e-1d62a25d0032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ 2-7 ë²”ì£¼í˜• ì»¬ëŸ¼ì„ Nì°¨ì›ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "# categorical_columns ì•ˆì— ìˆëŠ” ê° ë²”ì£¼í˜• ì»¬ëŸ¼ë§ˆë‹¤, ëª‡ ê°œì˜ ê³ ìœ  ì¹´í…Œê³ ë¦¬ê°€ ìˆëŠ”ì§€ ì„¼ë‹¤\n",
    "\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "# (col_size, embedding_dim) í˜•íƒœì˜ íŠœí”Œì„ ë§Œë“ ë‹¤\n",
    "# col_size: í•´ë‹¹ ë²”ì£¼í˜• ë³€ìˆ˜ì˜ ì¹´í…Œê³ ë¦¬ ê°œìˆ˜ (= ì„ë² ë”© lookup í…Œì´ë¸” í¬ê¸°)\n",
    "# embedding_dim: ì„ë² ë”© ë²¡í„° ì°¨ì› ìˆ˜\n",
    "# ë³´í†µ ê²½í—˜ì ìœ¼ë¡œ (ì¹´í…Œê³ ë¦¬ ê°œìˆ˜+1)//2ë¥¼ ì“°ê³ , ìµœëŒ€ 50ìœ¼ë¡œ ì œí•œ > 78í˜ì´ì§€ ì½”ë“œ 2-7 ìƒë‹¨ ì„¤ëª… \n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de38aa0b",
   "metadata": {
    "id": "de38aa0b"
   },
   "outputs": [],
   "source": [
    "# ì½”ë“œ 2-8 ë°ì´í„°ì„¸íŠ¸ ë¶„ë¦¬\n",
    "\n",
    "total_records = 1728\n",
    "test_records = int(total_records * .2) # 20%ë¥¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì‚¬ìš©\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46eb162b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1715779120682,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "46eb162b",
    "outputId": "6204c0ee-5140-46fe-99ce-b25e67c871de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1383\n",
      "345\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ 2-9 ë°ì´í„°ì„¸íŠ¸ ë¶„ë¦¬ í™•ì¸\n",
    "print(len(categorical_train_data))\n",
    "print(len(train_outputs))\n",
    "print(len(categorical_test_data))\n",
    "print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa67ca",
   "metadata": {
    "id": "2eaa67ca"
   },
   "outputs": [],
   "source": [
    "# ì½”ë“œ 2-10 ëª¨ë¸ì˜ ë„¤íŠ¸ì›Œí¬ êµ¬ì„±\n",
    "class Model(nn.Module): #nn.Moduleì„ ìƒì†ë°›ëŠ”ë‹¤\n",
    "    def __init__(self, embedding_size, output_size, layers, p=0.4):#ê°ì²´ ìƒì„±ì, ëª¨ë¸ì— ì‚¬ìš©ë  íŒŒë¼ë¯¸í„° ì „ë‹¬\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols # ì…ë ¥ì¸µì˜ í¬ê¸°ë¥¼ ì°¾ê¸° ìœ„í•´ ë²”ì£¼í˜• ì»¬ëŸ¼ ê°œìˆ˜ë¥¼ input_sizeì— ì €ì¥\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "        self.layers = nn.Sequential(*all_layers) #ëª¨ë“  ê³„ì¸µì„ ì „ë‹¬\n",
    "\n",
    "    def forward(self, x_categorical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4909ff0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715779161756,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4909ff0e",
    "outputId": "7ae94821-419f-4147-b4b9-5d761bcb3320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0-2): 3 x Embedding(4, 2)\n",
      "    (3-5): 3 x Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#ì½”ë“œ 2-11 ëª¨ë¸ ê°ì²´ ìƒì„±\n",
    "model = Model(categorical_embedding_sizes, 4, [200,100,50], p=0.4) #output_size = 4ë¡œ ì „ë‹¬ \n",
    "output_data = model(input_data)# forward() ë©”ì†Œë“œê°€ ì‹¤í–‰\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d59a6",
   "metadata": {
    "id": "301d59a6"
   },
   "outputs": [],
   "source": [
    "# ì½”ë“œ 2-12 ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ì •ì˜\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "# ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ìš© ì†ì‹¤ í•¨ìˆ˜.\n",
    "# ëª¨ë¸ ì¶œë ¥(ë¡œì§“, softmax ì „)ê³¼ ì •ë‹µ ë ˆì´ë¸”ì„ ë¹„êµí•´ ì˜¤ì°¨(ì†ì‹¤)ë¥¼ ê³„ì‚°\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Adam ìµœì í™” ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì—…ë°ì´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "KyuD2fLKM7Px",
   "metadata": {
    "id": "KyuD2fLKM7Px"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ìš¸ê¸°ê°€ 0ì¸ x: -0.4999999999999997\n",
      "í•´ë‹¹ ì§€ì ì—ì„œì˜ y ê°’: 5.75\n"
     ]
    }
   ],
   "source": [
    "# ì£¼ì–´ì§„ í•¨ìˆ˜ ì •ì˜\n",
    "def func(x): #sum(yi - yi_hat)**2\n",
    "    return 5 * x ** 2 + 5 * x + 7\n",
    "\n",
    "# ë„í•¨ìˆ˜(ë¯¸ë¶„) ê³„ì‚°\n",
    "def derivative(x):\n",
    "    return 10 * x + 5\n",
    "\n",
    "# ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‚¬ìš©í•˜ì—¬ ê¸°ìš¸ê¸°ê°€ 0ì¸ ì§€ì  ì°¾ê¸°\n",
    "def gradient_descent(learning_rate, initial_x, epochs):\n",
    "    x = initial_x\n",
    "    for _ in range(epochs):\n",
    "        gradient = derivative(x)\n",
    "        x = x - learning_rate * gradient\n",
    "    return x\n",
    "\n",
    "# í•™ìŠµë¥ , ì´ˆê¸°ê°’, ë°˜ë³µ íšŸìˆ˜ ì„¤ì •\n",
    "learning_rate = 0.01\n",
    "initial_x = 0.0\n",
    "epochs = 1000\n",
    "\n",
    "# ê²½ì‚¬ í•˜ê°•ë²• ì ìš©í•˜ì—¬ ê¸°ìš¸ê¸°ê°€ 0ì¸ ì§€ì  ì°¾ê¸°\n",
    "optimal_x = gradient_descent(learning_rate, initial_x, epochs)\n",
    "optimal_y = func(optimal_x)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"ê¸°ìš¸ê¸°ê°€ 0ì¸ x:\", optimal_x)\n",
    "print(\"í•´ë‹¹ ì§€ì ì—ì„œì˜ y ê°’:\", optimal_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c313f",
   "metadata": {
    "id": "3d5c313f"
   },
   "outputs": [],
   "source": [
    "# ì½”ë“œ 2-13 GPU/CPU ì‚¬ìš© ì§€ì •\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56492e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56492e5b",
    "outputId": "51e99adc-0975-422f-eb01-20719c4e3bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 1.58690417\n",
      "epoch:  26 loss: 1.32208347\n",
      "epoch:  51 loss: 1.25037670\n",
      "epoch:  76 loss: 1.14533412\n",
      "epoch: 101 loss: 1.04376388\n",
      "epoch: 126 loss: 0.94333309\n",
      "epoch: 151 loss: 0.82459933\n",
      "epoch: 176 loss: 0.75102794\n",
      "epoch: 201 loss: 0.70688218\n",
      "epoch: 226 loss: 0.67204970\n",
      "epoch: 251 loss: 0.65042794\n",
      "epoch: 276 loss: 0.62593251\n",
      "epoch: 301 loss: 0.61263412\n",
      "epoch: 326 loss: 0.60477704\n",
      "epoch: 351 loss: 0.58988392\n",
      "epoch: 376 loss: 0.58695173\n",
      "epoch: 401 loss: 0.57759738\n",
      "epoch: 426 loss: 0.57076532\n",
      "epoch: 451 loss: 0.57889175\n",
      "epoch: 476 loss: 0.56059849\n",
      "epoch: 500 loss: 0.5716277361\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ 2-14 ëª¨ë¸ í•™ìŠµ\n",
    "epochs = 500\n",
    "aggregated_losses = []\n",
    "train_outputs = train_outputs.to(device=device, dtype=torch.int64)\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data).to(device)\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f1035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd2f1035",
    "outputId": "130d32d1-a203-4208-e327-eabb367e46fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.55816710\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ 2-15 í…ŒìŠ¤íŠ¸ ë°ì´í„°ì„¸íŠ¸ë¡œ ëª¨ë¸ ì˜ˆì¸¡\n",
    "test_outputs = test_outputs.to(device=device, dtype=torch.int64)\n",
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data).to(device)\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6735f451",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6735f451",
    "outputId": "cdbe9174-23c8-43c2-e82d-e71f7607d11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.5791,  0.8695, -2.0905, -1.9746],\n",
      "        [ 2.3801,  1.2895, -3.7661, -3.5672],\n",
      "        [ 2.7393,  1.5828, -3.9005, -3.7467],\n",
      "        [ 2.9840,  2.0176, -4.0020, -4.0287],\n",
      "        [ 2.7245,  1.8273, -3.2561, -3.0924]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "#ì˜ˆì¸¡ ê°’ì€ 4ê°œ ê°’ > output_size = 4ë¡œ ì§€ì •\n",
    "print(y_val[:5]) # ìµœëŒ€ ê°’ì„ ê°€ì§„ ì¸ë±ìŠ¤ë¡œ ë¶„ë¥˜í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acf59f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5acf59f2",
    "outputId": "f9a2ec26-2e2c-419c-d959-9c720b90bec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ 2-17 ê°€ì¥ í° ê°’ì„ ê°–ëŠ” ì¸ë±ìŠ¤ í™•ì¸ \n",
    "y_val = np.argmax(y_val.cpu().numpy(), axis=1)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e16502",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7e16502",
    "outputId": "91fbee59-4b85-4bbc-9854-25da410bcd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[258   1]\n",
      " [ 86   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86       259\n",
      "           1       0.00      0.00      0.00        86\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.38      0.50      0.43       345\n",
      "weighted avg       0.56      0.75      0.64       345\n",
      "\n",
      "0.7478260869565218\n"
     ]
    }
   ],
   "source": [
    "# ì½”ë“œ 2-18 í…ŒìŠ¤íŠ¸ ë°ì´í„°ì„¸íŠ¸ë¥¼ ì‚¬ìš©í•œ ì •í™•ë„ í™•ì¸ \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "test_outputs=test_outputs.cpu().numpy()\n",
    "print(confusion_matrix(test_outputs,y_val))\n",
    "print(classification_report(test_outputs,y_val))\n",
    "print(accuracy_score(test_outputs, y_val))\n",
    "#confusion matrixì— ëŒ€í•œ ì„¤ëª…: 85-86í˜ì´ì§€\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9HAW0ADKWTM4",
   "metadata": {
    "id": "9HAW0ADKWTM4"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "Vzrg4SeHdw65",
   "metadata": {
    "id": "Vzrg4SeHdw65"
   },
   "source": [
    "êµ¬ê¸€ë§: 2023.04.18 ì£¼í”¼í„°ë…¸íŠ¸ë¶ VSCode ì—°ë™, ê°€ìƒí™˜ê²½ ë§Œë“¤ê¸°, GPUì‚¬ìš© í™˜ê²½ ì„¸íŒ…(ì—ëŸ¬ í•´ê²° ë°©ë²•), ì°¨ìœ ë¹ˆÂ·2023ë…„ 4ì›” 20ì¼"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
