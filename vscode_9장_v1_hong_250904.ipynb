{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1.1 자연어처리 용어 및 프로세스\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9970,
     "status": "ok",
     "timestamp": 1716274240944,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "SB_fwiJ73Bxg",
    "outputId": "d6dd2601-893c-44f6-c1a0-eb717fd01773"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.2.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.9.1-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\nlpys312\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading regex-2025.9.1-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Using cached click-8.2.1-py3-none-any.whl (102 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, joblib, click, nltk\n",
      "\n",
      "   -------- ------------------------------- 1/5 [regex]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ---------------- ----------------------- 2/5 [joblib]\n",
      "   ------------------------ --------------- 3/5 [click]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   -------------------------------- ------- 4/5 [nltk]\n",
      "   ---------------------------------------- 5/5 [nltk]\n",
      "\n",
      "Successfully installed click-8.2.1 joblib-1.5.2 nltk-3.9.1 regex-2025.9.1 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8251,
     "status": "ok",
     "timestamp": 1716274260240,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "fvMEQEf21-bT",
    "outputId": "28c8793b-deff-4514-b160-edf7132b5274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Is', 'it', 'possible', 'distinguishing', 'cats', 'and', 'dogs']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#코드 9-1 문장 토큰화\n",
    "import nltk\n",
    "nltk.download()\n",
    "#nltk.download() #NLTK Downloader 창에서 다운로드 버튼 클릭 > 완료되면 509페이지 상단의 창을 닫기 해야\n",
    "text=nltk.word_tokenize(\"Is it possible distinguishing cats and dogs\")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1716274307694,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "5DhuOQet1-bU",
    "outputId": "068d572e-ec9e-43e7-eb8a-6c640952a609"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 9-2 태깅에 필요한 자원 내려받기\n",
    "nltk.download('averaged_perceptron_tagger') # 태깅에 필요한 자원 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1716274334823,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "d66WVbQt1-bU",
    "outputId": "10482634-7745-4307-ada6-57af31180022"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Is', 'VBZ'),\n",
       " ('it', 'PRP'),\n",
       " ('possible', 'JJ'),\n",
       " ('distinguishing', 'VBG'),\n",
       " ('cats', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('dogs', 'NNS')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#코드 9-3 품사 태깅  \n",
    "nltk.pos_tag(text) # POS (Part-of-Speech): 품사 (명사, 동사, 형용사 등).\n",
    "# POS Tagging: 문장의 각 단어를 분석해 어떤 품사인지 라벨링하는 과정."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.1.2 자연어처리를 위한 라이브러리\n",
    "\n",
    "#### NLTK(Natural Language Tool Kit)\n",
    "\n",
    "-  NLTK 라이브러리 제공 기능: 말뭉치, 토큰 생성, 형태소 분석, 품사 태깅\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1716274429220,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "z3psY5CE1-bV",
    "outputId": "fd04e9c3-b7fc-4814-912e-03865d04c34f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['my', 'favorite', 'subject', 'is', 'math']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#코드 9-4nltk 라이브러리 호출 및 문장 정의\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "string1=\"my favorite subject is math\"\n",
    "string2=\"my favorite subject is math, english, economic and computer science\"\n",
    "nltk.word_tokenize(string1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 330,
     "status": "ok",
     "timestamp": 1701048431233,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "pB6IzpFb1-bW",
    "outputId": "981dccf6-0069-4e3a-9860-25c5f854ed5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my',\n",
       " 'favorite',\n",
       " 'subject',\n",
       " 'is',\n",
       " 'math',\n",
       " ',',\n",
       " 'english',\n",
       " ',',\n",
       " 'economic',\n",
       " 'and',\n",
       " 'computer',\n",
       " 'science']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 코드 9-5 단어 단위로 분리\n",
    "nltk.word_tokenize(string2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8794,
     "status": "ok",
     "timestamp": 1716274541987,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "j0gO3Wo73j_b",
    "outputId": "650645fe-37e2-44f0-c505-793dd7135e6f"
   },
   "outputs": [],
   "source": [
    "# KoNLPy - 한국어 처리를 위한 파이썬 라이브러리: 오픈소스 형태소 분석기\n",
    "# 기존 Kkma, Komoran, Hannanum, Twitter, Mecab 분석기를 설치\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'jpype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjpype\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mjpype\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimports\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mJVM path:\u001b[39m\u001b[33m\"\u001b[39m, jpype.getDefaultJVMPath())  \u001b[38;5;66;03m# 여기서 경로가 뜨면 좋음\u001b[39;00m\n\u001b[32m      3\u001b[39m jpype.startJVM(convertStrings=\u001b[38;5;28;01mFalse\u001b[39;00m)           \u001b[38;5;66;03m# 최소 옵션으로 기동\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'jpype'"
     ]
    }
   ],
   "source": [
    "import jpype, jpype.imports\n",
    "print(\"JVM path:\", jpype.getDefaultJVMPath())  # 여기서 경로가 뜨면 좋음\n",
    "jpype.startJVM(convertStrings=False)           # 최소 옵션으로 기동\n",
    "print(\"JVM started:\", jpype.isJVMStarted())\n",
    "jpype.shutdownJVM()\n",
    "print(\"JVM shutdown ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15828,
     "status": "ok",
     "timestamp": 1716274562486,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "5d_W9vuG1-bW",
    "outputId": "ad35852b-5f34-4343-db15-5486d23f5ccd"
   },
   "outputs": [],
   "source": [
    "#코드 9-6 라이브러리 호출 및 문장을 형태소로 변환\n",
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "print(komoran.morphs('딥러닝이 쉽나요? 어렵나요?')) # 텍스트를 형태로로 변환 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1716274608518,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "3Nv7cw_Q1-bX",
    "outputId": "70734185-2800-4aeb-cc11-690e2d6f9608"
   },
   "outputs": [],
   "source": [
    "# 코드 9-7 품사 태깅\n",
    "print(komoran.pos('소파 위에 있는 것이 고양이인가요? 강아지인가요?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KoNLPy 주요 기능:\n",
    "\n",
    "  > 형태소 분석과 품사 태깅\n",
    "\n",
    "  > 517페이지 그림 9-14 형태소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gensim: \n",
    "\n",
    "  - 파이썬에서 제공하는 word2vec 라이브러리\n",
    "\n",
    "  - Gensim 주요 기능: 임베딩: 워드투벡터, 토픽 모델링, LDA\n",
    "\n",
    "    > LDA (잠재 디리클레 할당): 각 문서가 여러 토픽의 혼합으로 이루어지고, 각 토픽은 여러 단어의 분포로 표현된다고 가정하는 확률 모델\n",
    "\n",
    "      >> 문서 = 여러 토픽의 확률적 혼합\n",
    "\n",
    "      >> 토픽 = 단어들의 확률적 분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8434,
     "status": "ok",
     "timestamp": 1716274712899,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "GeXI3Icg82DF",
    "outputId": "88b3e2a6-9657-4f6a-ebb3-aa090c4e6462"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
      "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
      "  Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 7.6/24.0 MB 39.0 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 16.0/24.0 MB 40.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.1/24.0 MB 33.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.5/24.0 MB 27.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 24.9 MB/s  0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 6.8/15.5 MB 32.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.2/15.5 MB 34.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 27.1 MB/s  0:00:00\n",
      "Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
      "   ---------------------------------------- 0.0/45.9 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 5.5/45.9 MB 28.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 10.5/45.9 MB 27.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 13.6/45.9 MB 22.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.9/45.9 MB 23.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 22.5/45.9 MB 21.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 28.3/45.9 MB 22.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 35.4/45.9 MB 23.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 42.5/45.9 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  45.9/45.9 MB 25.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 45.9/45.9 MB 23.6 MB/s  0:00:01\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Installing collected packages: wrapt, numpy, smart-open, scipy, gensim\n",
      "\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   -------- ------------------------------- 1/5 [numpy]\n",
      "   ---------------- ----------------------- 2/5 [smart-open]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   ------------------------ --------------- 3/5 [scipy]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   -------------------------------- ------- 4/5 [gensim]\n",
      "   ---------------------------------------- 5/5 [gensim]\n",
      "\n",
      "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.3.0.post1 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U gensim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 사이킷런 제공 텍스트 처리 라이브러리\n",
    "\n",
    "  > CountVectorizer\n",
    "\n",
    "  > Tfidfvectorizer\n",
    "\n",
    "  > hashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #9.2 전처리\n",
    "\n",
    "- 519페이지 그림 9-15 텍스트 전처리 과정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.1 결측치 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 29819,
     "status": "ok",
     "timestamp": 1701050420283,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "xxzs5HLM1-bY",
    "outputId": "145bef18-5762-4896-ee36-1ae115fdbaad"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 코드 9-8 결측치를 확인할 데이터 호출\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mchap09/data/class2.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m df\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# 코드 9-8 결측치를 확인할 데이터 호출\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('chap09/data/class2.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1701050458485,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "qcyP1Gby1-bZ",
    "outputId": "1c51125d-2e3d-4c28-bdba-eba205c802d4"
   },
   "outputs": [],
   "source": [
    "# 코드 9-9 결측치 개수 확인\n",
    "df.isnull().sum()# isnull() 결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1701050468962,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "3QtocWqI1-bZ",
    "outputId": "a8e6fc26-4c1b-4689-c077-0156dc553359"
   },
   "outputs": [],
   "source": [
    "# 코드 9-10 결측치 비율\n",
    "df.isnull().sum() / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 329,
     "status": "ok",
     "timestamp": 1701050487212,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Bf-a6n2o1-bZ",
    "outputId": "08b5bd06-59cc-4dba-9dea-db8b7fc6bf33"
   },
   "outputs": [],
   "source": [
    "# 코드 9-11 결측치 삭제 처리\n",
    "df = df.dropna(how='all') # 모든 행이 NaN일때 만 삭제\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "ok",
     "timestamp": 1701050507728,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "u4hKwuS21-ba",
    "outputId": "ff4623b4-ab9d-4958-fb90-c57527931f67"
   },
   "outputs": [],
   "source": [
    "# 코드 9-12 결측치 삭제 처리\n",
    "df1 = df.dropna() # 데이터에 하나라도 NaN이 있으면 행을 삭제\n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 343,
     "status": "ok",
     "timestamp": 1701050520097,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "8CV0LM1U1-ba",
    "outputId": "446897fc-7d4b-426b-989a-0164aa030fdb"
   },
   "outputs": [],
   "source": [
    "# 코드 9-13 결측치를 0으로 채우기\n",
    "df2=df.fillna(0)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 345,
     "status": "ok",
     "timestamp": 1701050529158,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "l6QFuYtM1-ba",
    "outputId": "cac41bd7-f766-40ed-ea5b-9bf8c9bf6f33"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 코드 9-14 결측치를 평균으로 채우기\n",
    "df['x'].fillna(df['x'].mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.2.2 토큰화\n",
    "\n",
    "- 문장 토큰화: 마침표, 느낌표, 물음표로 문장들을 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1716274934367,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "rvbbdP6J1-bb",
    "outputId": "f021a2cd-f5d6-4153-b262-0582f01b1ca1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 코드 9-15 문장 토큰화\n",
    "from nltk import sent_tokenize\n",
    "text_sample = 'Natural Language Processing, or NLP, is the process of extracting the meaning, or intent, behind human language. In the field of Conversational artificial intelligence (AI), NLP allows machines and applications to understand the intent of human language inputs, and then generate appropriate responses, resulting in a natural conversation flow.'\n",
    "tokenized_sentences = sent_tokenize(text_sample)\n",
    "print(tokenized_sentences) # 결과는 [ ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1716274941236,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "DNoEMa0G1-bb",
    "outputId": "56a5f29c-d8a0-4aee-af91-6a2e38a5fcef"
   },
   "outputs": [],
   "source": [
    "# 9-16 단어 토큰화\n",
    "from nltk import word_tokenize\n",
    "sentence = \" This book is for deep learning learners\"\n",
    "words = word_tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 936,
     "status": "ok",
     "timestamp": 1716274947777,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "1yK6zlzp1-bb",
    "outputId": "e505754a-59fa-4f24-8db2-8ca817f7e04d"
   },
   "outputs": [],
   "source": [
    "# 코드 9-17 아포스트로피가 포함된 문장에서 단어 토큰화\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "sentence = \"it’s nothing that you don’t already know except most people aren’t aware of how their inner world works.\"\n",
    "words = WordPunctTokenizer().tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alCAe55m1-bc"
   },
   "outputs": [],
   "source": [
    "#한국어 토큰화 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "executionInfo": {
     "elapsed": 236217,
     "status": "ok",
     "timestamp": 1716275980503,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "W031R3Xy1-bc",
    "outputId": "822b2765-b500-46d1-d468-e2d9c0bb4e60"
   },
   "outputs": [],
   "source": [
    "# 코드 9-18 라이브러리 호출 및 데이터세트 준비\n",
    "import csv\n",
    "from konlpy.tag import Okt\n",
    "from gensim.models import word2vec\n",
    "\n",
    "f = open(r'chap09/data/ratings_train.txt', 'r', encoding='utf-8')\n",
    "rdr = csv.reader(f, delimiter='\\t')\n",
    "rdw = list(rdr)\n",
    "f.close()\n",
    "##3분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 811350,
     "status": "ok",
     "timestamp": 1716276824539,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "p4Zfa7fy1-bc",
    "outputId": "27b8f7b9-2326-4ee6-c578-38ba0f660b9d"
   },
   "outputs": [],
   "source": [
    "#코드 9-19 오픈 소스 형태소 분석기 호출\n",
    "twitter = Okt() #KoNLPy 안에는 여러 분석기 중의 하나 \n",
    "# Okt는 “Open Korea Text”의 약자로, 원래는 Twitter 형태소 분석기였는데 버전 0.4.5부터 이름이 Okt로 바뀌었다.\n",
    "\n",
    "result = []\n",
    "for line in rdw:\n",
    "    malist = twitter.pos( line[1], norm=True, stem=True) # 형태소 분석\n",
    "    r = []\n",
    "    for word in malist:\n",
    "        if not word[1] in [\"Josa\",\"Eomi\",\"Punctuation\"]: #조사, 어미, 문장 부호 제외 처리\n",
    "            r.append(word[0])\n",
    "    rl = (\" \".join(r)).strip()\n",
    "    result.append(rl)\n",
    "    print(rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5jphGhM1-bc"
   },
   "outputs": [],
   "source": [
    "# 코드 9-20 형태소 저장\n",
    "with open(\"NaverMovie.nlp\",'w', encoding='utf-8') as fp:\n",
    "    fp.write(\"\\n\".join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124692,
     "status": "ok",
     "timestamp": 1700797515282,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "8pFZB6Zl1-bc",
    "outputId": "4ee76c3c-5e11-497a-a793-683e564e2f05"
   },
   "outputs": [],
   "source": [
    "# word2vec 모델 생성\n",
    "mData = word2vec.LineSentence(\"NaverMovie.nlp\")\n",
    "mModel =word2vec.Word2Vec(mData, vector_size=200, window=10, hs=1, min_count=2, sg=1)\n",
    "mModel.save(\"NaverMovie.model\") # 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-uGXO8q1-bd"
   },
   "outputs": [],
   "source": [
    "#9.2.3 불용어 제거\n",
    "\n",
    "# a, the 등의 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 523,
     "status": "ok",
     "timestamp": 1701051823660,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "fswJRUdz1-bd",
    "outputId": "ac915bc5-e019-4ad0-c90f-537b658a21d1"
   },
   "outputs": [],
   "source": [
    "# 코드 9-22\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sample_text = \"One of the first things that we ask ourselves is what are the pros and cons of any task we perform.\"\n",
    "text_tokens = word_tokenize(sample_text)\n",
    "\n",
    "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words('english')]\n",
    "print(\"불용어 제거 미적용:\", text_tokens, '\\n')\n",
    "print(\"불용어 제거 적용:\",tokens_without_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-CdqpCiz1-bd"
   },
   "outputs": [],
   "source": [
    "#9.2.4 어간 추출\n",
    "\n",
    "## 어간 추출은 사전에 없는 단어도 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1701052445706,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "WWOIrq2a1-bd",
    "outputId": "8ef14cea-7ec4-476f-d624-47085946c5c0"
   },
   "outputs": [],
   "source": [
    "# 9-27 포터 알고리즘 > nltk의 어간 추출\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "print(stemmer.stem('obesses'),stemmer.stem('obssesed'))\n",
    "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1701052451280,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "01tigA6Y1-be",
    "outputId": "4b1737fd-867f-42fe-98a8-a85477ce2313"
   },
   "outputs": [],
   "source": [
    "# 코드 9-24 랭커스터 알고리즘> nltk의 어간 추출 방법 > 어간 축소 정도가 크다\n",
    "from nltk.stem import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
    "print(stemmer.stem('standardizes'),stemmer.stem('standardization'))\n",
    "print(stemmer.stem('national'), stemmer.stem('nation'))\n",
    "print(stemmer.stem('absentness'), stemmer.stem('absently'))\n",
    "print(stemmer.stem('tribalical'), stemmer.stem('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1691,
     "status": "ok",
     "timestamp": 1701052471747,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "FmDrLu8o1-be",
    "outputId": "eba69ba6-1c93-41b7-cb3f-cf55c2861309"
   },
   "outputs": [],
   "source": [
    "#코드 9-25 표제어 추출(Lemmatization)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(stemmer.stem('obsesses'),stemmer.stem('obsessed'))\n",
    "print(lemma.lemmatize('standardizes'),lemma.lemmatize('standardization'))\n",
    "print(lemma.lemmatize('national'), lemma.lemmatize('nation'))\n",
    "print(lemma.lemmatize('absentness'), lemma.lemmatize('absently'))\n",
    "print(lemma.lemmatize('tribalical'), lemma.lemmatize('tribalicalized'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 319,
     "status": "ok",
     "timestamp": 1701052492627,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "ToPk2j-o1-be",
    "outputId": "15a99017-f03c-45ee-c8ec-e28d44397f47"
   },
   "outputs": [],
   "source": [
    "# 코드 9-26 표제어 추출시에 품사 정보 제공 > 정확한 어근 단어 추출\n",
    "print(lemma.lemmatize('obsesses', 'v'),lemma.lemmatize('obsessed','a'))\n",
    "print(lemma.lemmatize('standardizes','v'),lemma.lemmatize('standardization','n'))\n",
    "print(lemma.lemmatize('national','a'), lemma.lemmatize('nation','n'))\n",
    "print(lemma.lemmatize('absentness','n'), lemma.lemmatize('absently','r'))\n",
    "print(lemma.lemmatize('tribalical','a'), lemma.lemmatize('tribalicalized','v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SAvUCXOj1-be"
   },
   "outputs": [],
   "source": [
    "# 9.2.5정규화(Normalization) - 데이터 스케일\n",
    "\n",
    "## 531페이지 상단 문단의 4~6 라인:이해 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tiae7QiK1-be"
   },
   "outputs": [],
   "source": [
    "# 코드 9-27 라이브러리 호출\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1701052664610,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "eJihCVzF1-be",
    "outputId": "54ef1d36-3dc8-4621-b0f8-11cacdc62226"
   },
   "outputs": [],
   "source": [
    "# 코드 9-28 데이터세트 경로 지정 및 훈련/테스트 데이터 분리\n",
    "df = pd.read_csv('data/diabetes.csv')\n",
    "X = df[df.columns[:-1]]\n",
    "y = df['Outcome']\n",
    "\n",
    "X = X.values\n",
    "y = torch.tensor(y.values)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 462,
     "status": "ok",
     "timestamp": 1701052673663,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "qVB7vCw41-bf",
    "outputId": "b06becc6-224d-4306-9487-97f3aec3b4e9"
   },
   "outputs": [],
   "source": [
    "# 코드 9-29 훈련/테스트 데이터 정규화\n",
    "ms = MinMaxScaler() # 0 ~ 1 사이의 값으로 스케일 조정\n",
    "ss = StandardScaler() # 평균 0, 분산 1로 변경\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "X_test = ss.fit_transform(X_test)\n",
    "y_train =y_train.reshape(-1, 1)\n",
    "y_test =y_test.reshape(-1, 1)\n",
    "y_train = ms.fit_transform(y_train)\n",
    "y_test = ms.fit_transform(y_test)\n",
    "print(X_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kaO6Xq2a1-bf"
   },
   "outputs": [],
   "source": [
    "# 코드 9-30 커스텀 데이터세트\n",
    "class customdataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.len = len(self.X)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index], self.y[index]\n",
    "    # __getitem__은 리스트나 딕셔너리처럼 [] 인덱싱 연산을 가능하게 하는 파이썬의 특별 메서드\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = customdataset(X, y)\n",
    "print(data[0])    # -> 내부적으로 data.__getitem__(0) 호출\n",
    "\n",
    "yTorch의 DataLoader는 배치 단위로 데이터를 불러올 때 내부적으로 __getitem__을 반복 호출.\n",
    "\n",
    "for batch_X, batch_y in loader:\n",
    "    # 이 시점에서 DataLoader가 내부적으로\n",
    "    # dataset.__getitem__(index) 여러 번 호출해서 batch를 구성\n",
    "    print(batch_X, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMlSfytT1-bf"
   },
   "outputs": [],
   "source": [
    "# 코드 9-31 데이터로더에 데이터 담기\n",
    "train_data = customdataset(torch.FloatTensor(X_train),\n",
    "                       torch.FloatTensor(y_train))\n",
    "test_data = customdataset(torch.FloatTensor(X_test),\n",
    "                       torch.FloatTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zxnuX1yJ1-bf"
   },
   "outputs": [],
   "source": [
    "# 코드 9-32 네트워크 생성\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.layer_1 = nn.Linear(8, 64, bias=True) # 컬럼 특성이 8개\n",
    "        self.layer_2 = nn.Linear(64, 64, bias=True)\n",
    "        self.layer_out = nn.Linear(64, 1, bias=True) # 출력이 0 또는 1 값\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2034,
     "status": "ok",
     "timestamp": 1701053072891,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "8UZ5lUeU1-bf",
    "outputId": "6ec9a871-8f48-4883-f4d2-d0c34118be75"
   },
   "outputs": [],
   "source": [
    "# 코드 9-33 손실 함수와 옵티마이저 지정\n",
    "epochs = 1000+1\n",
    "print_epoch = 100\n",
    "LEARNING_RATE = 1e-2\n",
    "\n",
    "model = binaryClassification()\n",
    "model.to(device)\n",
    "print(model)\n",
    "BCE = nn.BCEWithLogitsLoss() # 이진 교차 엔트로피 + 시그모이드 함수가 결합\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mo2Mzb9q1-bg"
   },
   "outputs": [],
   "source": [
    "# 코드 9-34 모델 성능 측정 함수 정의\n",
    "def accuracy(y_pred, y_test):\n",
    "    y_pred_tag = torch.round(torch.sigmoid(y_pred))\n",
    "    correct_results_sum = (y_pred_tag == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25225,
     "status": "ok",
     "timestamp": 1701053118146,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "N-Z3_qMQ1-bg",
    "outputId": "81553baf-f903-4661-a5cb-b2aa94f99464"
   },
   "outputs": [],
   "source": [
    "# 코드 9-35 모델 학습\n",
    "for epoch in range(epochs):\n",
    "    iteration_loss = 0. # 변수를 0으로 초기화\n",
    "    iteration_accuracy = 0.\n",
    "\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader): # 데이터로더에서 훈련데이터를 배치 크기만큼 가져온다\n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X.float()).to(device) #독립변수를 모델에 적용하여 훈련\n",
    "        loss = BCE(y_pred, y.reshape(-1,1).float()) # 손실함수 적용\n",
    "\n",
    "        iteration_loss += loss # 오차값 누적\n",
    "        iteration_accuracy += accuracy(y_pred, y) # 모델 성능을 변수에 누적하여 저장\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if(epoch % print_epoch == 0):\n",
    "        print('Train: epoch: {0} - loss: {1:.5f}; acc: {2:.3f}'.format(epoch, iteration_loss/(i+1), iteration_accuracy/(i+1)))\n",
    "\n",
    "    iteration_loss = 0.\n",
    "    iteration_accuracy = 0.\n",
    "    model.eval()\n",
    "    for i, data in enumerate(test_loader):# 데이터로더에서 배치 크기만큼 읽어온다\n",
    "        X, y = data\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X.float()).to(device)\n",
    "        loss = BCE(y_pred, y.reshape(-1,1).float())\n",
    "        iteration_loss += loss\n",
    "        iteration_accuracy += accuracy(y_pred, y)\n",
    "    if(epoch % print_epoch == 0):\n",
    "        print('Test: epoch: {0} - loss: {1:.5f}; acc: {2:.3f}'.format(epoch, iteration_loss/(i+1), iteration_accuracy/(i+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ydLQrpIu1-bg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "nlpys312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
